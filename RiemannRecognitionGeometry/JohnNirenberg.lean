/-
Copyright (c) 2025. All rights reserved.
Released under MIT license.

# John-Nirenberg Inequality for BMO Functions

This module provides the John-Nirenberg inequality, which is the key tool
for proving the Fefferman-Stein BMO→Carleson embedding.

## Main Results

- `johnNirenberg_exp_decay`: The exponential distribution bound for BMO functions
- `bmo_Lp_bound`: BMO functions are in L^p for all p < ∞
- `measure_le_of_average_gt`: Key measure bound from averaging

## Mathematical Background

The John-Nirenberg inequality (1961) states that for f ∈ BMO:

  |{x ∈ I : |f(x) - f_I| > λ}| ≤ C₁ · |I| · exp(-C₂ · λ / ‖f‖_BMO)

This exponential decay is the key property that distinguishes BMO from L^∞.
It implies:
1. f ∈ L^p(loc) for all p < ∞
2. The Poisson extension gradient is controlled

## Implementation Notes

This file incorporates key lemmas from the Carleson project's BMO formalization,
particularly the measure-average relationships and CZ decomposition infrastructure.

## References

- John & Nirenberg (1961), "On functions of bounded mean oscillation", CPAM 14
- Garnett, "Bounded Analytic Functions", Chapter VI
- Stein, "Harmonic Analysis", Chapter IV
- Carleson Project BMO formalization (github.com/fpvandoorn/carleson)
-/

import RiemannRecognitionGeometry.Basic
import RiemannRecognitionGeometry.FeffermanStein
import Mathlib.MeasureTheory.Integral.SetIntegral
import Mathlib.MeasureTheory.Integral.Average
import Mathlib.MeasureTheory.Measure.Lebesgue.Basic
import Mathlib.Analysis.SpecialFunctions.Log.Basic
import Mathlib.Analysis.SpecialFunctions.Pow.Real
import Mathlib.Analysis.SpecialFunctions.Pow.Integral
import Mathlib.Analysis.SpecialFunctions.Gamma.Basic

noncomputable section
open Real MeasureTheory Set

/--
Remaining analytic inputs for the Calderón-Zygmund and John-Nirenberg theory.

This bundles the “hard analysis” facts that are currently assumed into a single surface,
instead of scattering multiple independent `axiom`s across the file.
-/
structure JohnNirenbergAssumptions : Prop where
  /-- **AXIOM (Calderón-Zygmund Decomposition)**: Standard CZ decomposition at level t. -/
  czDecomposition_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
      (_hf_int : IntegrableOn f (Icc a b))
      (t : ℝ) (_ht_pos : t > 0)
      (_ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|) :
      ∃ _cz : CZDecomposition f (Icc a b) t, True

  /-- **AXIOM (CZ Good/Bad Split)**: Full CZ decomposition with good/bad function split. -/
  czDecompFull_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
      (_hf_int : IntegrableOn f (Icc a b))
      (t : ℝ) (_ht_pos : t > 0)
      (_ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|) :
      ∃ _cz : CZDecompFull f (Icc a b) t, True

  /-- **AXIOM (Good-λ Inequality)**: The key measure-theoretic bound for John-Nirenberg. -/
  goodLambda_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
      (M : ℝ) (_hM_pos : M > 0)
      (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
      (t : ℝ) (_ht : t > M) :
      volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
      ENNReal.ofReal (1/2) * volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t - M}

  /-- **AXIOM (JN Base Case)**: First step of John-Nirenberg (k=1 case). -/
  jn_first_step_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
      (M : ℝ) (_hM_pos : M > 0)
      (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M) :
      volume {x ∈ Icc a b | |f x - intervalAverage f a b| > M} ≤
      ENNReal.ofReal ((b - a) / 2)

  /-- **AXIOM (BMO L^p Bound)**: BMO functions are in L^p for all 1 ≤ p < ∞. -/
  bmo_Lp_bound_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
      (M : ℝ) (_hM_pos : M > 0)
      (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
      (p : ℝ) (_hp : 1 ≤ p) :
      (b - a)⁻¹ * ∫ x in Icc a b, |f x - intervalAverage f a b|^p ≤
      (JN_C1 * (2 * Real.exp 1)^p * Real.Gamma (p + 1)) * M^p

  /-- **AXIOM (BMO Kernel Bound)**: BMO functions have controlled kernel integrals. -/
  bmo_kernel_bound_axiom (f : ℝ → ℝ) (K : ℝ → ℝ)
      (M : ℝ) (_hM_pos : M > 0)
      (_h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
      (_hK_int : Integrable K)
      (c : ℝ) :
      |∫ t, K t * (f t - c)| ≤ (2 * JN_C1) * M * ∫ t, |K t|

axiom jnAssumptions : JohnNirenbergAssumptions

namespace RiemannRecognitionGeometry

/-! ## Numerical Constants

Standard numerical bounds used in the John-Nirenberg proof.
-/

/-- The mathematical constant e satisfies e < 2.72.

    **Numerical fact**: e ≈ 2.71828... < 2.72

    **Proof**: Uses Mathlib's `exp_bound` which bounds |exp(x) - Σₖ xᵏ/k!| for |x| ≤ 1.
    For n = 7 terms, the partial sum S₇ < 2.719 and error < 1/4000, giving exp(1) < 2.72. -/
lemma exp_one_lt_272 : Real.exp 1 < 2.72 := by
  -- Use exp_bound with n = 7
  have h_bound := @Real.exp_bound 1 (by norm_num : |1| ≤ (1:ℝ)) 7 (by norm_num : 0 < 7)

  -- Simplify the error bound: 8/(5040*7) ≤ 1/4000
  have h_err_simp : (|1| : ℝ)^7 * ((7:ℕ).succ / ((7:ℕ).factorial * (7:ℕ))) ≤ (1:ℝ)/4000 := by
    simp only [abs_one, one_pow, Nat.succ_eq_add_one, Nat.factorial]
    norm_num

  -- So |exp 1 - S_7| ≤ 1/4000
  have h_bound' : |Real.exp 1 - ∑ m ∈ Finset.range 7, (1:ℝ)^m / m.factorial| ≤ 1/4000 :=
    h_bound.trans h_err_simp

  -- From |a - b| ≤ ε we get a ≤ b + ε
  have h_upper : Real.exp 1 ≤ ∑ m ∈ Finset.range 7, (1:ℝ)^m / m.factorial + 1/4000 := by
    have := abs_sub_le_iff.mp h_bound'
    linarith [this.2]

  -- S_7 = 1 + 1 + 1/2 + 1/6 + 1/24 + 1/120 + 1/720 = 1957/720 < 2.719
  have h_S7_bound : ∑ m ∈ Finset.range 7, (1:ℝ)^m / m.factorial < 2.719 := by
    simp only [Finset.range_succ, Finset.range_zero, Finset.sum_empty, Finset.sum_insert,
               Finset.not_mem_empty, not_false_eq_true, Nat.factorial, pow_zero, pow_one,
               Nat.cast_one, Nat.cast_ofNat, one_pow]
    norm_num [Nat.factorial]

  have h_sum_bound : ∑ m ∈ Finset.range 7, (1:ℝ)^m / m.factorial + 1/4000 < 2.72 := by
    calc ∑ m ∈ Finset.range 7, (1:ℝ)^m / m.factorial + 1/4000
        < 2.719 + 1/4000 := by linarith [h_S7_bound]
      _ < 2.72 := by norm_num

  linarith [h_upper, h_sum_bound]

/-! ## Dyadic Intervals

Dyadic intervals are the building blocks for the Calderón-Zygmund decomposition.
-/

/-- A dyadic interval of generation n starting at k · 2^(-n). -/
structure DyadicInterval where
  generation : ℕ  -- n: the "level" (higher = smaller intervals)
  index : ℤ       -- k: which interval at this level
  deriving DecidableEq

/-- The left endpoint of a dyadic interval. -/
def DyadicInterval.left (D : DyadicInterval) : ℝ :=
  D.index * (2 : ℝ)^(-(D.generation : ℤ))

/-- The right endpoint of a dyadic interval. -/
def DyadicInterval.right (D : DyadicInterval) : ℝ :=
  (D.index + 1) * (2 : ℝ)^(-(D.generation : ℤ))

/-- The length of a dyadic interval is 2^(-n). -/
def DyadicInterval.length (D : DyadicInterval) : ℝ :=
  (2 : ℝ)^(-(D.generation : ℤ))

/-- The interval as a set. -/
def DyadicInterval.toSet (D : DyadicInterval) : Set ℝ :=
  Ico D.left D.right

/-- Dyadic interval length is positive. -/
lemma DyadicInterval.length_pos (D : DyadicInterval) : D.length > 0 := by
  unfold length
  exact zpow_pos (by norm_num : (2:ℝ) > 0) _

/-- Dyadic intervals have positive measure. -/
lemma DyadicInterval.measure_pos (D : DyadicInterval) :
    0 < volume D.toSet := by
  unfold DyadicInterval.toSet
  rw [Real.volume_Ico]
  apply ENNReal.ofReal_pos.mpr
  unfold DyadicInterval.left DyadicInterval.right
  have hlen := D.length_pos
  unfold DyadicInterval.length at hlen
  calc (D.index + 1) * (2:ℝ) ^ (-(D.generation:ℤ)) - D.index * (2:ℝ) ^ (-(D.generation:ℤ))
      = ((D.index + 1) - D.index) * (2:ℝ) ^ (-(D.generation:ℤ)) := by ring
    _ = (2:ℝ) ^ (-(D.generation:ℤ)) := by ring
    _ > 0 := hlen

/-- Dyadic intervals have nonzero measure. -/
lemma DyadicInterval.measure_ne_zero (D : DyadicInterval) :
    volume D.toSet ≠ 0 := ne_of_gt D.measure_pos

/-- Dyadic intervals have finite measure. -/
lemma DyadicInterval.measure_ne_top (D : DyadicInterval) :
    volume D.toSet ≠ ⊤ := by
  unfold DyadicInterval.toSet
  rw [Real.volume_Ico]
  exact ENNReal.ofReal_ne_top

/-- Dyadic intervals are measurable sets. -/
lemma DyadicInterval.measurable (D : DyadicInterval) :
    MeasurableSet D.toSet := by
  unfold DyadicInterval.toSet
  exact measurableSet_Ico

/-- The parent of a dyadic interval (one level up). -/
def DyadicInterval.parent (D : DyadicInterval) : DyadicInterval :=
  { generation := D.generation - 1
    index := D.index / 2 }

/-- The left child of a dyadic interval. -/
def DyadicInterval.leftChild (D : DyadicInterval) : DyadicInterval :=
  { generation := D.generation + 1
    index := 2 * D.index }

/-- The right child of a dyadic interval. -/
def DyadicInterval.rightChild (D : DyadicInterval) : DyadicInterval :=
  { generation := D.generation + 1
    index := 2 * D.index + 1 }

/-! ## Average and Oscillation on Sets

This section provides the key measure-average relationships needed for the
John-Nirenberg inequality. The central lemma `measure_le_of_average_gt` shows
that if the average of |f| on a set exceeds a threshold λ, then the measure
of that set is bounded by (1/λ) times the integral of |f|.
-/

/-- The average of f over a set S with finite positive measure. -/
def setAverage (f : ℝ → ℝ) (S : Set ℝ) (μ : Measure ℝ := volume) : ℝ :=
  if _h : μ S ≠ 0 ∧ μ S ≠ ⊤ then
    (μ S).toReal⁻¹ * ∫ x in S, f x ∂μ
  else 0

/-- The Mathlib-style set average using ⨍ notation. -/
def mathlib_setAverage (f : ℝ → ℝ) (S : Set ℝ) (μ : Measure ℝ := volume) : ℝ :=
  ⨍ x in S, f x ∂μ

/-- Our setAverage equals Mathlib's ⨍ notation when measure is positive and finite. -/
lemma setAverage_eq_mathlib_average {f : ℝ → ℝ} {S : Set ℝ}
    (hS_ne : volume S ≠ 0) (hS_fin : volume S ≠ ⊤) :
    setAverage f S = ⨍ x in S, f x := by
  unfold setAverage
  have h : volume S ≠ 0 ∧ volume S ≠ ⊤ := ⟨hS_ne, hS_fin⟩
  simp only [dif_pos h]
  rw [MeasureTheory.setAverage_eq, smul_eq_mul]

/-- The set average of |f| equals the integral divided by the measure.
    This is a key identity for converting between average bounds and integral bounds. -/
lemma setAverage_abs_eq_integral_div {S : Set ℝ} {μ : Measure ℝ} (hμ : μ S ≠ ⊤)
    (hμ_pos : μ S ≠ 0) {f : ℝ → ℝ} (_ : IntegrableOn f S μ) :
    ⨍ x in S, |f x| ∂μ = (∫ x in S, |f x| ∂μ) / (μ S).toReal := by
  rw [MeasureTheory.setAverage_eq, smul_eq_mul]
  have hpos : 0 < (μ S).toReal := ENNReal.toReal_pos hμ_pos hμ
  field_simp [ne_of_gt hpos]

/-- From an average lower bound, derive an integral lower bound.
    If `level < ⨍_S |f|`, then `level * μ(S) < ∫_S |f|`. -/
lemma integral_gt_of_setAverage_gt {S : Set ℝ} {μ : Measure ℝ}
    {f : ℝ → ℝ} (hf : IntegrableOn f S μ) {level : ℝ}
    (havg : level < ⨍ x in S, |f x| ∂μ) (hμ : μ S ≠ 0) (hμ' : μ S ≠ ⊤) :
    level * (μ S).toReal < ∫ x in S, |f x| ∂μ := by
  have hpos : 0 < (μ S).toReal := ENNReal.toReal_pos hμ hμ'
  rw [setAverage_abs_eq_integral_div hμ' hμ hf] at havg
  exact (lt_div_iff₀ hpos).mp havg

/-- **Key Lemma (from Carleson Project)**: If the average exceeds a threshold,
    then the measure is bounded by the integral.

    This is the key estimate used in the CZ decomposition: from `level < ⨍ |f|` we derive
    that `μ(S) ≤ (1/level) · ∫ |f|`.

    **Proof outline**:
    1. From `level < ⨍_S |f| = (∫_S |f|) / μ(S)` we get `level · μ(S) < ∫_S |f|`
    2. Dividing by `level` gives `μ(S) < (1/level) · ∫_S |f|`
    3. Convert to `ℝ≥0∞` and relate Bochner integral to Lebesgue integral -/
lemma measure_le_of_average_gt {S : Set ℝ} {μ : Measure ℝ} (hS : MeasurableSet S)
    {f : ℝ → ℝ} (hf : IntegrableOn f S μ) {level : ℝ} (hlevel : 0 < level)
    (havg : level < ⨍ x in S, |f x| ∂μ) (hμ : μ S ≠ 0) (hμ' : μ S ≠ ⊤) :
    μ S ≤ ENNReal.ofReal (1 / level) * ∫⁻ x in S, ‖f x‖₊ ∂μ := by
  -- Step 1: From level < ⨍ |f| we get level * μ(S) < ∫ |f|
  have hpos : 0 < (μ S).toReal := ENNReal.toReal_pos hμ hμ'
  have h1 : level * (μ S).toReal < ∫ x in S, |f x| ∂μ :=
    integral_gt_of_setAverage_gt hf havg hμ hμ'
  -- Step 2: Hence μ(S) < (1/level) * ∫ |f|
  have h1' : (μ S).toReal * level < ∫ x in S, |f x| ∂μ := by linarith
  have h2 : (μ S).toReal < level⁻¹ * ∫ x in S, |f x| ∂μ := by
    have h3 : (μ S).toReal < (∫ x in S, |f x| ∂μ) / level := by
      rw [lt_div_iff₀ hlevel]; exact h1'
    calc (μ S).toReal < (∫ x in S, |f x| ∂μ) / level := h3
      _ = (∫ x in S, |f x| ∂μ) * level⁻¹ := by rw [div_eq_mul_inv]
      _ = level⁻¹ * ∫ x in S, |f x| ∂μ := by ring
  -- Step 3: The integral of |f| is nonnegative
  have hint : 0 ≤ ∫ x in S, |f x| ∂μ := setIntegral_nonneg hS (fun _ _ => abs_nonneg _)
  -- Step 4: Convert to ENNReal
  have h3 : (μ S).toReal ≤ level⁻¹ * ∫ x in S, |f x| ∂μ := h2.le
  -- Step 5: ENNReal conversion
  calc μ S = ENNReal.ofReal (μ S).toReal := (ENNReal.ofReal_toReal hμ').symm
    _ ≤ ENNReal.ofReal (level⁻¹ * ∫ x in S, |f x| ∂μ) := ENNReal.ofReal_le_ofReal h3
    _ = ENNReal.ofReal level⁻¹ * ENNReal.ofReal (∫ x in S, |f x| ∂μ) := by
        rw [ENNReal.ofReal_mul (inv_nonneg.mpr hlevel.le)]
    _ = ENNReal.ofReal (1 / level) * ENNReal.ofReal (∫ x in S, |f x| ∂μ) := by
        rw [one_div]
    _ ≤ ENNReal.ofReal (1 / level) * ∫⁻ x in S, ‖f x‖₊ ∂μ := by
        gcongr
        -- Convert Bochner integral of |f| to Lebesgue integral of ‖f‖₊
        rw [ofReal_integral_eq_lintegral_ofReal hf.abs (ae_of_all _ (fun _ => abs_nonneg _))]
        apply lintegral_mono
        intro x
        -- Need: ENNReal.ofReal |f x| ≤ ‖f x‖₊
        -- |f x| = ‖f x‖ for real numbers, and ofReal ‖·‖ = ‖·‖₊ (as ENNReal)
        simp only [← Real.norm_eq_abs]
        rw [ofReal_norm_eq_enorm, enorm_eq_nnnorm]

/-- The oscillation triangle inequality: for f ∈ BMO, the difference of averages
    between nested sets is bounded by the BMO seminorm times a factor.

    **Mathematical Statement**:
    If B' ⊂ B and both have finite positive measure, then:
    |⨍_{B'} f - ⨍_B f| ≤ (μ(B)/μ(B')) · ⨍_B |f - ⨍_B f|

    This is proved by:
    |⨍_{B'} f - ⨍_B f| = |⨍_{B'} (f - ⨍_B f)| ≤ ⨍_{B'} |f - ⨍_B f|
    and using that B' ⊂ B to bound the average over B' by a scaled average over B.

    **Proof** (following Carleson project BMO infrastructure):
    1. Linearity: ⨍_{B'} f - c = ⨍_{B'} (f - c) where c = ⨍_B f
    2. Jensen: |⨍_{B'} (f - c)| ≤ ⨍_{B'} |f - c|
    3. Integral monotonicity: ∫_{B'} |f - c| ≤ ∫_B |f - c| since B' ⊆ B
    4. Measure scaling: (μ B')⁻¹ · ∫_B = (μ B / μ B') · (μ B)⁻¹ · ∫_B -/
lemma oscillation_triangle_helper {f : ℝ → ℝ} {B B' : Set ℝ} {μ : Measure ℝ}
    (_hB_meas : MeasurableSet B) (_hB'_meas : MeasurableSet B')
    (hB'_sub : B' ⊆ B)
    (hμB : μ B ≠ 0) (hμB' : μ B' ≠ 0)
    (hμB_fin : μ B ≠ ⊤) (hμB'_fin : μ B' ≠ ⊤)
    (hf_int : IntegrableOn f B μ) :
    |⨍ x in B', f x ∂μ - ⨍ x in B, f x ∂μ| ≤
      (μ B).toReal / (μ B').toReal * ⨍ x in B, |f x - ⨍ y in B, f y ∂μ| ∂μ := by
  -- Let c = ⨍_B f be the average over B
  set c := ⨍ x in B, f x ∂μ with hc_def

  have hμB_pos : 0 < (μ B).toReal := ENNReal.toReal_pos hμB hμB_fin
  have hμB'_pos : 0 < (μ B').toReal := ENNReal.toReal_pos hμB' hμB'_fin
  have hμB_ne : (μ B).toReal ≠ 0 := hμB_pos.ne'
  have hμB'_ne : (μ B').toReal ≠ 0 := hμB'_pos.ne'

  -- Integrability setup
  have hf_int_B' : IntegrableOn f B' μ := hf_int.mono_set hB'_sub
  have hconst_int_B : IntegrableOn (fun _ => c) B μ := integrableOn_const.mpr (Or.inr hμB_fin.lt_top)
  have hconst_int_B' : IntegrableOn (fun _ => c) B' μ := integrableOn_const.mpr (Or.inr hμB'_fin.lt_top)
  have hfc_int : IntegrableOn (fun x => f x - c) B μ := hf_int.sub hconst_int_B
  have hfc_int_B' : IntegrableOn (fun x => f x - c) B' μ := hf_int_B'.sub hconst_int_B'
  have hfc_abs_int : IntegrableOn (fun x => |f x - c|) B μ := hfc_int.abs
  have hfc_abs_int_B' : IntegrableOn (fun x => |f x - c|) B' μ := hfc_int_B'.abs

  -- Step 1: Linearity - ⨍_{B'} f - c = ⨍_{B'} (f - c)
  have h_linear : ⨍ x in B', f x ∂μ - c = ⨍ x in B', (f x - c) ∂μ := by
    rw [MeasureTheory.setAverage_eq, MeasureTheory.setAverage_eq]
    simp only [smul_eq_mul]
    rw [MeasureTheory.integral_sub hf_int_B' hconst_int_B']
    rw [MeasureTheory.setIntegral_const]
    simp only [smul_eq_mul]
    -- (μ.restrict B').real univ = (μ B').toReal by definition
    have hμB'_real : (μ B').toReal = (μ B').toReal := rfl
    have hrestr : (μ.restrict B' Set.univ).toReal = (μ B').toReal := by
      rw [Measure.restrict_apply_univ]
    field_simp [hμB'_ne, hrestr]

  -- Step 2: Jensen - |⨍_{B'} (f - c)| ≤ ⨍_{B'} |f - c|
  have h_jensen : |⨍ x in B', (f x - c) ∂μ| ≤ ⨍ x in B', |f x - c| ∂μ := by
    rw [MeasureTheory.setAverage_eq, MeasureTheory.setAverage_eq]
    simp only [smul_eq_mul]
    rw [abs_mul]
    have h_inv_nonneg : 0 ≤ (μ B').toReal⁻¹ := inv_nonneg.mpr hμB'_pos.le
    rw [abs_of_nonneg h_inv_nonneg]
    apply mul_le_mul_of_nonneg_left _ h_inv_nonneg
    -- |∫ f| ≤ ∫ |f| via norm_integral_le_integral_norm
    calc |∫ x in B', (f x - c) ∂μ|
        = ‖∫ x in B', (f x - c) ∂μ‖ := (Real.norm_eq_abs _).symm
      _ ≤ ∫ x in B', ‖f x - c‖ ∂μ := MeasureTheory.norm_integral_le_integral_norm _
      _ = ∫ x in B', |f x - c| ∂μ := by simp only [Real.norm_eq_abs]

  -- Step 3: Integral monotonicity - ∫_{B'} |f - c| ≤ ∫_B |f - c| since B' ⊆ B
  have h_int_mono : ∫ x in B', |f x - c| ∂μ ≤ ∫ x in B, |f x - c| ∂μ := by
    apply MeasureTheory.setIntegral_mono_set hfc_abs_int
    · exact ae_of_all _ (fun x => abs_nonneg _)
    · exact hB'_sub.eventuallyLE

  -- Step 4: Scale by measure ratio
  -- ⨍_{B'} |f - c| = (μ B')⁻¹ · ∫_{B'} |f - c| ≤ (μ B')⁻¹ · ∫_B |f - c|
  --                = (μ B / μ B') · (μ B)⁻¹ · ∫_B |f - c| = (μ B / μ B') · ⨍_B |f - c|
  have h_avg_bound : ⨍ x in B', |f x - c| ∂μ ≤ (μ B).toReal / (μ B').toReal * ⨍ x in B, |f x - c| ∂μ := by
    rw [MeasureTheory.setAverage_eq, MeasureTheory.setAverage_eq]
    simp only [smul_eq_mul]
    -- (μ B / μ B') * ((μ B)⁻¹ * ∫_B) = (μ B')⁻¹ * ∫_B  (algebra)
    have h_rhs : (μ B).toReal / (μ B').toReal * ((μ B).toReal⁻¹ * ∫ x in B, |f x - c| ∂μ) =
                 (μ B').toReal⁻¹ * ∫ x in B, |f x - c| ∂μ := by
      have := hμB_ne
      have := hμB'_ne
      field_simp
      ring
    rw [h_rhs]
    apply mul_le_mul_of_nonneg_left h_int_mono
    exact inv_nonneg.mpr hμB'_pos.le

  -- Combine all steps
  calc |⨍ x in B', f x ∂μ - c|
      = |⨍ x in B', (f x - c) ∂μ| := by rw [h_linear]
    _ ≤ ⨍ x in B', |f x - c| ∂μ := h_jensen
    _ ≤ (μ B).toReal / (μ B').toReal * ⨍ x in B, |f x - c| ∂μ := h_avg_bound

/-- The mean oscillation of f over a set S. -/
def setMeanOscillation (f : ℝ → ℝ) (S : Set ℝ) (μ : Measure ℝ := volume) : ℝ :=
  if _h : μ S ≠ 0 ∧ μ S ≠ ⊤ then
    (μ S).toReal⁻¹ * ∫ x in S, |f x - setAverage f S μ| ∂μ
  else 0

/-- f is in BMO' if all its mean oscillations are bounded by some M > 0. -/
def InBMO' (f : ℝ → ℝ) : Prop :=
  ∃ M : ℝ, M > 0 ∧ ∀ a b : ℝ, a < b → setMeanOscillation f (Icc a b) ≤ M

/-! ## Calderón-Zygmund Decomposition

The CZ decomposition splits a function at level λ into "good" and "bad" parts.
This is the key technical tool for proving the John-Nirenberg inequality.

The structure here follows the Carleson project's `CZDecompDoubling` which provides
a more comprehensive framework for doubling metric measure spaces.
-/

/-- For a locally integrable function f and level t > 0, the Calderón-Zygmund
    decomposition finds maximal dyadic intervals where the average exceeds t.

    **Mathematical Statement**:
    Given f ∈ L¹(I₀) and t > (1/|I₀|)∫_{I₀}|f|, there exists a collection
    {Qⱼ} of disjoint dyadic subintervals of I₀ such that:
    1. t < (1/|Qⱼ|)∫_{Qⱼ}|f| ≤ 2t  (selection criterion)
    2. |f(x)| ≤ t for a.e. x ∈ I₀ \ ⋃ⱼQⱼ  (good part bound)
    3. Σⱼ|Qⱼ| ≤ (1/t)∫_{I₀}|f|  (total measure bound)
-/
structure CZDecomposition (f : ℝ → ℝ) (I₀ : Set ℝ) (t : ℝ) where
  /-- The "bad" dyadic intervals where average > t -/
  badIntervals : Set DyadicInterval
  /-- Bad intervals are subsets of I₀ -/
  badIntervals_subset : ∀ D ∈ badIntervals, D.toSet ⊆ I₀
  /-- The bad intervals are countable (follows from finite measure) -/
  badIntervals_countable : badIntervals.Countable
  /-- The bad intervals are pairwise disjoint -/
  disjoint : ∀ D₁ D₂ : DyadicInterval, D₁ ∈ badIntervals → D₂ ∈ badIntervals →
             D₁ ≠ D₂ → Disjoint D₁.toSet D₂.toSet
  /-- Each bad interval has average between t and 2t -/
  avgBound : ∀ D ∈ badIntervals,
             t < setAverage (|f ·|) D.toSet ∧ setAverage (|f ·|) D.toSet ≤ 2 * t
  /-- On the good part, |f| ≤ t a.e. -/
  goodBound : ∀ᵐ x ∂volume, x ∈ I₀ →
              (∀ D ∈ badIntervals, x ∉ D.toSet) → |f x| ≤ t

/-- Extended CZ decomposition structure with good/bad function decomposition.
    Follows the Carleson project's approach. -/
structure CZDecompFull (f : ℝ → ℝ) (I₀ : Set ℝ) (level : ℝ) extends CZDecomposition f I₀ level where
  /-- The good part of the decomposition (equals f outside bad intervals,
      equals the interval average on each bad interval) -/
  goodPart : ℝ → ℝ
  /-- The bad parts (one for each bad interval) -/
  badParts : DyadicInterval → ℝ → ℝ
  /-- The decomposition is valid: f = g + ∑ᵢ bᵢ -/
  decomp : ∀ᵐ x ∂volume, f x = goodPart x + ∑' D : badIntervals, badParts D.val x
  /-- The good part is bounded by 2·level -/
  good_bound : ∀ᵐ x ∂volume, |goodPart x| ≤ 2 * level
  /-- Each bad part is supported on its interval -/
  bad_support : ∀ D : badIntervals, Function.support (badParts D.val) ⊆ D.val.toSet
  /-- Each bad part has zero mean -/
  bad_mean_zero : ∀ D : badIntervals, ∫ x in D.val.toSet, badParts D.val x = 0

/-- **Single Interval Bound**: For a dyadic interval D with avgBound, we have
    volume(D) ≤ (1/level) * ∫_D |f|.

    This is the building block for the full CZ measure bound. -/
lemma cz_single_interval_bound (f : ℝ → ℝ) (level : ℝ) (hlevel : 0 < level)
    (D : DyadicInterval)
    (hf_int : IntegrableOn f D.toSet)
    (havg : level < setAverage (|f ·|) D.toSet) :
    volume D.toSet ≤ ENNReal.ofReal (1 / level) * ∫⁻ x in D.toSet, ‖f x‖₊ := by
  have h_ne := D.measure_ne_zero
  have h_fin := D.measure_ne_top
  rw [setAverage_eq_mathlib_average h_ne h_fin] at havg
  exact measure_le_of_average_gt D.measurable hf_int hlevel havg h_ne h_fin

/-- **THEOREM**: The CZ covering balls have total measure controlled by ‖f‖₁/λ.

    **Proof outline**:
    1. From `level < ⨍_{B_n} |f|`, we get `level * μ(B_n) ≤ ∫_{B_n} |f|`,
       hence `μ(B_n) ≤ (1/level) * ∫_{B_n} |f|` (via `cz_single_interval_bound`).
    2. Sum over n: `∑ μ(B_n) ≤ (1/level) * ∑ ∫_{B_n} |f|`.
    3. By disjointness and `lintegral_iUnion`: `∑ ∫_{B_n} |f| = ∫_{⋃ B_n} |f|`.
    4. By monotonicity: `∫_{⋃ B_n} |f| ≤ ∫_{I₀} |f|`.
    5. Hence `∑ μ(B_n) ≤ (1/level) * ∫_{I₀} |f| = (1/level) * ‖f‖_{L¹(I₀)}`.

    **Mathlib lemmas**: measure_le_of_average_gt, tsum_le_tsum, lintegral_iUnion, lintegral_mono_set

    Reference: Stein, "Harmonic Analysis", Chapter I -/
theorem czDecomposition_measure_bound (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b) (level : ℝ)
    (hlevel : 0 < level) (cz : CZDecomposition f (Icc a b) level)
    (hf_int : IntegrableOn f (Icc a b)) :
    ∑' D : cz.badIntervals, volume D.val.toSet ≤
      ENNReal.ofReal (1 / level) * ∫⁻ x in Icc a b, ‖f x‖₊ := by
  -- Use countability to get a Countable instance
  haveI : Countable cz.badIntervals := cz.badIntervals_countable.to_subtype

  -- Step 1: Each term bound using cz_single_interval_bound
  have h_each : ∀ D : cz.badIntervals,
      volume D.val.toSet ≤ ENNReal.ofReal (1 / level) * ∫⁻ x in D.val.toSet, ‖f x‖₊ := by
    intro ⟨D, hD⟩
    have havg := cz.avgBound D hD
    have h_D_sub : D.toSet ⊆ Icc a b := cz.badIntervals_subset D hD
    have hf_int_D : IntegrableOn f D.toSet := hf_int.mono h_D_sub le_rfl
    exact cz_single_interval_bound f level hlevel D hf_int_D havg.1

  -- Step 2: Bound by sum of local integrals
  have h_sum_bound : ∑' D : cz.badIntervals, volume D.val.toSet ≤
      ∑' D : cz.badIntervals, ENNReal.ofReal (1 / level) * ∫⁻ x in D.val.toSet, ‖f x‖₊ :=
    tsum_le_tsum h_each ENNReal.summable ENNReal.summable

  -- Step 3: Pull out constant
  have h_pull_const : ∑' D : cz.badIntervals, ENNReal.ofReal (1 / level) * ∫⁻ x in D.val.toSet, ‖f x‖₊ =
      ENNReal.ofReal (1 / level) * ∑' D : cz.badIntervals, ∫⁻ x in D.val.toSet, ‖f x‖₊ :=
    ENNReal.tsum_mul_left

  -- Step 4: Pairwise disjoint
  have h_pairwise_disj : Pairwise (Function.onFun Disjoint (fun D : cz.badIntervals => D.val.toSet)) := by
    intro ⟨D₁, hD₁⟩ ⟨D₂, hD₂⟩ hne
    have hne' : D₁ ≠ D₂ := fun h => hne (Subtype.eq h)
    exact cz.disjoint D₁ D₂ hD₁ hD₂ hne'

  -- Step 5: Each set is measurable
  have h_meas : ∀ D : cz.badIntervals, MeasurableSet D.val.toSet :=
    fun ⟨D, _⟩ => D.measurable

  -- Step 6: Union is subset of Icc a b
  have h_union_sub : (⋃ D : cz.badIntervals, D.val.toSet) ⊆ Icc a b := by
    intro x hx
    simp only [mem_iUnion] at hx
    obtain ⟨⟨D, hD⟩, hx_in_D⟩ := hx
    exact cz.badIntervals_subset D hD hx_in_D

  -- Step 7: By lintegral_iUnion for disjoint sets, sum = integral over union
  have h_sum_eq_union : ∑' D : cz.badIntervals, ∫⁻ x in D.val.toSet, ‖f x‖₊ =
      ∫⁻ x in (⋃ D : cz.badIntervals, D.val.toSet), ‖f x‖₊ := by
    rw [lintegral_iUnion h_meas h_pairwise_disj]

  -- Step 8: Integral over union ≤ integral over Icc a b
  have h_union_le : ∫⁻ x in (⋃ D : cz.badIntervals, D.val.toSet), ‖f x‖₊ ≤
      ∫⁻ x in Icc a b, ‖f x‖₊ :=
    lintegral_mono_set h_union_sub

  calc ∑' D : cz.badIntervals, volume D.val.toSet
      ≤ ∑' D : cz.badIntervals, ENNReal.ofReal (1 / level) * ∫⁻ x in D.val.toSet, ‖f x‖₊ := h_sum_bound
    _ = ENNReal.ofReal (1 / level) * ∑' D : cz.badIntervals, ∫⁻ x in D.val.toSet, ‖f x‖₊ := h_pull_const
    _ = ENNReal.ofReal (1 / level) * ∫⁻ x in (⋃ D : cz.badIntervals, D.val.toSet), ‖f x‖₊ := by
        rw [h_sum_eq_union]
    _ ≤ ENNReal.ofReal (1 / level) * ∫⁻ x in Icc a b, ‖f x‖₊ := mul_le_mul_left' h_union_le _

/-- **THEOREM**: CZ decomposition exists (from hypothesis).

    The Calderón-Zygmund decomposition exists for any locally integrable function
    and level t above the average.

    **Construction** (stopping-time algorithm):
    1. Start with I₀ = [a, b] and dyadic children
    2. For each dyadic interval Q ⊂ I₀:
       - If ⨍_Q |f| > t and Q is minimal with this property, add Q to bad set
       - Otherwise, continue subdividing
    3. By the Lebesgue differentiation theorem, this terminates a.e.

    **Properties**:
    - Bad intervals are maximal among those with average > t
    - Hence average is between t and 2t (doubling from parent)
    - Good set has |f| ≤ t a.e. (by maximality)
    - Measure Bound: Σ|Q_j| ≤ (1/t) · ∫_{I₀} |f|

    Takes the existence as an explicit hypothesis, acknowledging this is
    a classical result requiring dyadic infrastructure.

    Reference: Stein, "Harmonic Analysis", Chapter I -/
theorem czDecomposition_exists (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (_hf_int : IntegrableOn f (Icc a b))
    (t : ℝ) (_ht_pos : t > 0)
    (_ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|)
    (h_exists : ∃ _cz : CZDecomposition f (Icc a b) t, True) :
    ∃ _cz : CZDecomposition f (Icc a b) t, True := h_exists

/-! ### Calderón-Zygmund Construction Machinery -/

/-- A dyadic interval is "bad" at threshold t if its average exceeds t. -/
def DyadicInterval.isBadAt (D : DyadicInterval) (f : ℝ → ℝ) (t : ℝ) : Prop :=
  setAverage (|f ·|) D.toSet > t

/-- A dyadic interval is contained in [a,b]. -/
def DyadicInterval.isContainedIn (D : DyadicInterval) (a b : ℝ) : Prop :=
  D.left ≥ a ∧ D.right ≤ b

/-- A dyadic interval is "maximal bad" if bad and parent is good or outside. -/
def DyadicInterval.isMaximalBadAt (D : DyadicInterval) (f : ℝ → ℝ) (t : ℝ) (a b : ℝ) : Prop :=
  D.isBadAt f t ∧ D.isContainedIn a b ∧
  (¬ D.parent.isContainedIn a b ∨ ¬ D.parent.isBadAt f t)

/-- The set of maximal bad dyadic intervals. -/
def maximalBadIntervals (f : ℝ → ℝ) (a b : ℝ) (t : ℝ) : Set DyadicInterval :=
  { D | D.isMaximalBadAt f t a b }

/- Dyadic nesting is proven below as `dyadic_nesting`. -/

/-- **THEOREM (Dyadic Same-Gen Disjoint)**: Same-generation dyadic intervals with different
    indices are disjoint.

    At generation n, half-open intervals [k·2^(-n), (k+1)·2^(-n)) partition ℝ.

    **Proof**: If k₁ ≠ k₂, then wlog k₁ < k₂. Then D₁.right = (k₁+1)·s ≤ k₂·s = D₂.left,
    so D₁ ∩ D₂ = ∅ since D₁ = [k₁·s, (k₁+1)·s) and D₂ = [k₂·s, (k₂+1)·s).

    Note: This requires half-open intervals `Ico`; with `Icc` adjacent intervals share
    a boundary point. -/
theorem dyadic_same_gen_disjoint (D₁ D₂ : DyadicInterval)
    (heq : D₁.generation = D₂.generation) (hidx : D₁.index ≠ D₂.index) :
    Disjoint D₁.toSet D₂.toSet := by
  -- Scale factor s = 2^(-n) where n = D₁.generation = D₂.generation
  set s := (2:ℝ)^(-(D₁.generation:ℤ)) with hs_def
  have hs_pos : 0 < s := zpow_pos (by norm_num) _
  have hs_eq : (2:ℝ)^(-(D₂.generation:ℤ)) = s := by rw [← heq]
  -- D₁ = [k₁·s, (k₁+1)·s), D₂ = [k₂·s, (k₂+1)·s)
  -- If k₁ ≠ k₂, wlog k₁ < k₂ (by symmetry)
  rcases Ne.lt_or_lt hidx with hlt | hlt
  · -- Case k₁ < k₂: D₁.right ≤ D₂.left
    rw [Set.disjoint_iff]
    intro x ⟨hx1, hx2⟩
    simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
               Set.mem_Ico] at hx1 hx2
    -- hx1: k₁·s ≤ x < (k₁+1)·s
    -- hx2: k₂·s' ≤ x < (k₂+1)·s' where s' = 2^(-gen₂) = s
    have hx1_upper : x < (D₁.index + 1) * s := hx1.2
    have hx2_lower : D₂.index * (2:ℝ)^(-(D₂.generation:ℤ)) ≤ x := hx2.1
    rw [hs_eq] at hx2_lower
    -- From k₁ < k₂ (natural numbers): k₁ + 1 ≤ k₂
    have hidx' : D₁.index + 1 ≤ D₂.index := hlt
    have hcast : (D₁.index + 1 : ℝ) ≤ D₂.index := by
      exact_mod_cast hidx'
    -- So (k₁+1)·s ≤ k₂·s
    have hbound : (D₁.index + 1 : ℝ) * s ≤ D₂.index * s :=
      mul_le_mul_of_nonneg_right hcast (le_of_lt hs_pos)
    -- Contradiction: x < (k₁+1)·s ≤ k₂·s ≤ x
    linarith
  · -- Case k₂ < k₁: symmetric, D₂.right ≤ D₁.left
    rw [Set.disjoint_iff]
    intro x ⟨hx1, hx2⟩
    simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
               Set.mem_Ico] at hx1 hx2
    have hx1_lower : D₁.index * s ≤ x := hx1.1
    have hx2_upper : x < (D₂.index + 1) * (2:ℝ)^(-(D₂.generation:ℤ)) := hx2.2
    rw [hs_eq] at hx2_upper
    -- From k₂ < k₁ (natural numbers): k₂ + 1 ≤ k₁
    have hidx' : D₂.index + 1 ≤ D₁.index := hlt
    have hcast : (D₂.index + 1 : ℝ) ≤ D₁.index := by
      exact_mod_cast hidx'
    have hbound : (D₂.index + 1 : ℝ) * s ≤ D₁.index * s :=
      mul_le_mul_of_nonneg_right hcast (le_of_lt hs_pos)
    linarith

theorem dyadic_nesting (D₁ D₂ : DyadicInterval) (hgen : D₁.generation > D₂.generation) :
    Disjoint D₁.toSet D₂.toSet ∨ D₁.toSet ⊆ D₂.toSet := by
  -- Let n₁ > n₂ be the generations. Set m = n₁ - n₂ and d = 2^m.
  set n₁ : ℕ := D₁.generation
  set n₂ : ℕ := D₂.generation
  have hn₂_le : n₂ ≤ n₁ := Nat.le_of_lt hgen
  set m : ℕ := n₁ - n₂
  set d : ℤ := (2 : ℤ) ^ m
  have hd_pos : 0 < d := by
    have : (0 : ℤ) < (2 : ℤ) := by norm_num
    exact pow_pos this m
  have hd_ne0 : d ≠ 0 := ne_of_gt hd_pos

  -- Define the ancestor interval A at generation n₂ containing D₁.
  set q : ℤ := D₁.index / d
  let A : DyadicInterval := { generation := n₂, index := q }

  -- First show D₁ ⊆ A.
  have hD₁_sub_A : D₁.toSet ⊆ A.toSet := by
    intro x hx
    simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right, A, Set.mem_Ico] at hx ⊢

    have hs1_pos : 0 < (2 : ℝ) ^ (-(n₁ : ℤ)) := by
      exact zpow_pos (by norm_num : (0 : ℝ) < 2) _

    have hgen_eq : n₁ = n₂ + m := by
      have : n₁ = (n₁ - n₂) + n₂ := (Nat.sub_add_cancel hn₂_le).symm
      simpa [m, Nat.add_assoc, Nat.add_left_comm, Nat.add_comm] using this

    have hzpow_scale :
        (2 : ℝ) ^ (-(n₂ : ℤ)) = (2 : ℝ) ^ (m : ℤ) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
      have : (-(n₂ : ℤ)) = (m : ℤ) + (-(n₁ : ℤ)) := by
        have hn1z : (n₁ : ℤ) = (n₂ : ℤ) + (m : ℤ) := by
          exact_mod_cast hgen_eq
        linarith
      calc
        (2 : ℝ) ^ (-(n₂ : ℤ))
            = (2 : ℝ) ^ ((m : ℤ) + (-(n₁ : ℤ))) := by simp [this]
        _ = (2 : ℝ) ^ (m : ℤ) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
              simpa using
                (zpow_add₀ (a := (2 : ℝ)) (by norm_num : (2 : ℝ) ≠ 0) (m : ℤ) (-(n₁ : ℤ)))

    -- Integer inequalities for division by d: q*d ≤ index < (q+1)*d.
    have hq_mul_le : q * d ≤ D₁.index := by
      simpa [q] using (Int.ediv_mul_le D₁.index (b := d) hd_ne0)

    have hindex_lt : D₁.index < (q + 1) * d := by
      have hmod_lt : D₁.index % d < d := Int.emod_lt_of_pos D₁.index hd_pos
      have hdecomp : d * (D₁.index / d) + D₁.index % d = D₁.index :=
        Int.ediv_add_emod D₁.index d
      have hdecomp' : d * q + D₁.index % d = D₁.index := by simpa [q] using hdecomp
      have : D₁.index < d * q + d := by
        have : d * q + D₁.index % d < d * q + d := add_lt_add_left hmod_lt (d * q)
        simpa [hdecomp'] using this
      have hmul : d * q + d = (q + 1) * d := by ring
      simpa [hmul] using this

    -- Translate those integer inequalities into inequalities on endpoints.
    have hA_left_le_D₁_left :
        A.index * (2 : ℝ) ^ (-(n₂ : ℤ)) ≤ D₁.index * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
      have hd_cast : ((d : ℤ) : ℝ) = (2 : ℝ) ^ (m : ℤ) := by
        simp [d, Int.cast_pow, zpow_natCast]
      have hq_mul_leR : ((q * d : ℤ) : ℝ) ≤ (D₁.index : ℝ) := by
        exact_mod_cast hq_mul_le
      calc
        (A.index : ℝ) * (2 : ℝ) ^ (-(n₂ : ℤ))
            = (q : ℝ) * ((2 : ℝ) ^ (m : ℤ) * (2 : ℝ) ^ (-(n₁ : ℤ))) := by
                simp [A, hzpow_scale, mul_assoc]
        _ = ((q : ℝ) * (2 : ℝ) ^ (m : ℤ)) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by ring
        _ = ((q * d : ℤ) : ℝ) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
              simp [hd_cast, Int.cast_mul, mul_assoc]
        _ ≤ (D₁.index : ℝ) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
              exact mul_le_mul_of_nonneg_right hq_mul_leR (le_of_lt hs1_pos)

    have hD₁_right_le_A_right :
        ((D₁.index : ℝ) + 1) * (2 : ℝ) ^ (-(n₁ : ℤ)) ≤
          ((A.index : ℝ) + 1) * (2 : ℝ) ^ (-(n₂ : ℤ)) := by
      have hindex1_le : D₁.index + 1 ≤ (q + 1) * d := Int.add_one_le_of_lt hindex_lt
      have hindex1_leR : ((D₁.index + 1 : ℤ) : ℝ) ≤ ((q + 1) * d : ℤ) := by
        exact_mod_cast hindex1_le
      have hd_cast : ((d : ℤ) : ℝ) = (2 : ℝ) ^ (m : ℤ) := by
        simp [d, Int.cast_pow, zpow_natCast]
      have hcast_idx1 : ((D₁.index : ℝ) + 1) = ((D₁.index + 1 : ℤ) : ℝ) := by
        simp [Int.cast_add, Int.cast_one, add_comm, add_left_comm, add_assoc]
      have hcast_q1 : ((q + 1 : ℤ) : ℝ) = (q : ℝ) + 1 := by
        simp [Int.cast_add, Int.cast_one]
      calc
        ((D₁.index : ℝ) + 1) * (2 : ℝ) ^ (-(n₁ : ℤ))
            = ((D₁.index + 1 : ℤ) : ℝ) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
                rw [hcast_idx1]
        _ ≤ ((q + 1) * d : ℤ) * (2 : ℝ) ^ (-(n₁ : ℤ)) := by
              exact mul_le_mul_of_nonneg_right hindex1_leR (le_of_lt hs1_pos)
        _ = ((q + 1 : ℤ) : ℝ) * ((2 : ℝ) ^ (m : ℤ) * (2 : ℝ) ^ (-(n₁ : ℤ))) := by
              simp [Int.cast_mul, hd_cast, mul_assoc]
        _ = ((q + 1 : ℤ) : ℝ) * (2 : ℝ) ^ (-(n₂ : ℤ)) := by
              simp [hzpow_scale, mul_assoc]
        _ = ((A.index : ℝ) + 1) * (2 : ℝ) ^ (-(n₂ : ℤ)) := by
              simp [A, hcast_q1]

    constructor
    · exact le_trans hA_left_le_D₁_left hx.1
    · exact lt_of_lt_of_le hx.2 hD₁_right_le_A_right

  by_cases hq_eq : q = D₂.index
  · right
    have hn₂ : n₂ = D₂.generation := by rfl
    have hA_toSet : A.toSet = D₂.toSet := by
      simp [A, hn₂, DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right, hq_eq]
    simpa [hA_toSet] using hD₁_sub_A
  · left
    have hA_disj : Disjoint A.toSet D₂.toSet := by
      have hgen_eq : A.generation = D₂.generation := by
        have hn₂ : n₂ = D₂.generation := by rfl
        simp [A, hn₂]
      exact dyadic_same_gen_disjoint A D₂ hgen_eq hq_eq
    exact (Disjoint.mono_left hD₁_sub_A) hA_disj

/-- Dyadic trichotomy: disjoint, equal, or one contains the other.

    **Proof**: Uses `dyadic_nesting` axiom for different generations,
    and `dyadic_same_gen_disjoint` for same generation. -/
lemma DyadicInterval.trichotomy (D₁ D₂ : DyadicInterval) :
    Disjoint D₁.toSet D₂.toSet ∨ D₁ = D₂ ∨ D₁.toSet ⊆ D₂.toSet ∨ D₂.toSet ⊆ D₁.toSet := by
  rcases Nat.lt_trichotomy D₁.generation D₂.generation with hlt | heq | hgt
  · -- D₁ coarser (smaller gen), D₂ finer
    rcases dyadic_nesting D₂ D₁ hlt with hdisj | hsub
    · left; exact hdisj.symm
    · right; right; right; exact hsub
  · -- Same generation
    by_cases hidx : D₁.index = D₂.index
    · right; left
      cases D₁; cases D₂; simp only [mk.injEq]; exact ⟨heq, hidx⟩
    · left; exact dyadic_same_gen_disjoint D₁ D₂ heq hidx
  · -- D₁ finer (larger gen), D₂ coarser
    rcases dyadic_nesting D₁ D₂ hgt with hdisj | hsub
    · left; exact hdisj
    · right; right; left; exact hsub

/-
**NOTE**: The definition of `isMaximalBadAt` (parent is good or outside [a,b])
    is a LOCAL maximality condition that does NOT imply pairwise disjointness.
    Counterexample: D₁ ⊊ D₂ can both be "maximal bad" if there are good intervals
    between them.

    The actual disjointness in CZ decomposition comes from the CONSTRUCTION
    (stopping time process), which is encoded in the `disjoint` field of
    `CZDecomposition`, not derived from `isMaximalBadAt`.

    A stronger definition of maximality (no larger bad interval containing D)
    would imply disjointness, but the current definition doesn't. -/

/-- Left child is contained in parent.
    Key: 2^(-(n+1)) = 2^(-n)/2, so leftChild = [k·2^(-n), (k+1/2)·2^(-n)) ⊆ parent -/
lemma DyadicInterval.leftChild_subset (D : DyadicInterval) :
    D.leftChild.toSet ⊆ D.toSet := by
  intro x hx
  simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
             DyadicInterval.leftChild, Set.mem_Ico] at hx ⊢
  -- Normalize casts for consistent types
  have hx1 : (2 : ℝ) * ↑D.index * (2:ℝ)^(-((D.generation + 1):ℤ)) ≤ x := by
    convert hx.1 using 2; push_cast; ring
  have hx2 : x < (2 * ↑D.index + 1) * (2:ℝ)^(-((D.generation + 1):ℤ)) := by
    convert hx.2 using 2; push_cast; ring
  have h2pow : (2:ℝ)^(-((D.generation + 1):ℤ)) = (2:ℝ)^(-(D.generation:ℤ)) / 2 := by
    rw [show (-((D.generation + 1):ℤ) : ℤ) = -(D.generation:ℤ) - 1 from by omega]
    rw [zpow_sub₀ (by norm_num : (2:ℝ) ≠ 0), zpow_one]
  have hpos : (0:ℝ) < 2^(-(D.generation:ℤ)) := zpow_pos (by norm_num) _
  have hleft : (2 : ℝ) * ↑D.index * (2:ℝ)^(-((D.generation + 1):ℤ)) =
               ↑D.index * (2:ℝ)^(-(D.generation:ℤ)) := by rw [h2pow]; ring
  have hright : (2 * ↑D.index + 1) * (2:ℝ)^(-((D.generation + 1):ℤ)) =
                (↑D.index + 1/2) * (2:ℝ)^(-(D.generation:ℤ)) := by rw [h2pow]; ring
  constructor
  · calc ↑D.index * (2:ℝ)^(-(D.generation:ℤ))
        = (2 : ℝ) * ↑D.index * (2:ℝ)^(-((D.generation + 1):ℤ)) := hleft.symm
      _ ≤ x := hx1
  · calc x < (2 * ↑D.index + 1) * (2:ℝ)^(-((D.generation + 1):ℤ)) := hx2
      _ = (↑D.index + 1/2) * (2:ℝ)^(-(D.generation:ℤ)) := hright
      _ < (↑D.index + 1) * (2:ℝ)^(-(D.generation:ℤ)) := by nlinarith

/-- Right child is contained in parent.
    Key: 2^(-(n+1)) = 2^(-n)/2, so rightChild = [(k+1/2)·2^(-n), (k+1)·2^(-n)) ⊆ parent -/
lemma DyadicInterval.rightChild_subset (D : DyadicInterval) :
    D.rightChild.toSet ⊆ D.toSet := by
  intro x hx
  simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
             DyadicInterval.rightChild, Set.mem_Ico] at hx ⊢
  -- Normalize casts for consistent types
  have hx1 : (2 * ↑D.index + 1) * (2:ℝ)^(-((D.generation + 1):ℤ)) ≤ x := by
    convert hx.1 using 2; push_cast; ring
  have hx2 : x < (2 * ↑D.index + 2) * (2:ℝ)^(-((D.generation + 1):ℤ)) := by
    convert hx.2 using 2; push_cast; ring
  have h2pow : (2:ℝ)^(-((D.generation + 1):ℤ)) = (2:ℝ)^(-(D.generation:ℤ)) / 2 := by
    rw [show (-((D.generation + 1):ℤ) : ℤ) = -(D.generation:ℤ) - 1 from by omega]
    rw [zpow_sub₀ (by norm_num : (2:ℝ) ≠ 0), zpow_one]
  have hpos : (0:ℝ) < 2^(-(D.generation:ℤ)) := zpow_pos (by norm_num) _
  have hleft : (2 * ↑D.index + 1) * (2:ℝ)^(-((D.generation + 1):ℤ)) =
               (↑D.index + 1/2) * (2:ℝ)^(-(D.generation:ℤ)) := by rw [h2pow]; ring
  have hright : (2 * ↑D.index + 2) * (2:ℝ)^(-((D.generation + 1):ℤ)) =
                (↑D.index + 1) * (2:ℝ)^(-(D.generation:ℤ)) := by rw [h2pow]; ring
  constructor
  · calc ↑D.index * (2:ℝ)^(-(D.generation:ℤ))
        ≤ (↑D.index + 1/2) * (2:ℝ)^(-(D.generation:ℤ)) := by nlinarith
      _ = (2 * ↑D.index + 1) * (2:ℝ)^(-((D.generation + 1):ℤ)) := hleft.symm
      _ ≤ x := hx1
  · calc x < (2 * ↑D.index + 2) * (2:ℝ)^(-((D.generation + 1):ℤ)) := hx2
      _ = (↑D.index + 1) * (2:ℝ)^(-(D.generation:ℤ)) := hright

/-- Child has half the measure of parent.
    Proof: Child length = 2^(-(n+1)) = 2^(-n)/2 = parent.length/2 -/
lemma DyadicInterval.child_measure_half (D : DyadicInterval) :
    volume D.leftChild.toSet = volume D.toSet / 2 ∧
    volume D.rightChild.toSet = volume D.toSet / 2 := by
  have h2pow : (2:ℝ)^(-((D.generation + 1):ℤ)) = (2:ℝ)^(-(D.generation:ℤ)) / 2 := by
    rw [show (-((D.generation + 1):ℤ) : ℤ) = -(D.generation:ℤ) - 1 from by omega]
    rw [zpow_sub₀ (by norm_num : (2:ℝ) ≠ 0), zpow_one]
  have hpos : (0:ℝ) < 2^(-(D.generation:ℤ)) := zpow_pos (by norm_num) _
  -- Compute volumes using length
  have hvol_parent : volume D.toSet = ENNReal.ofReal D.length := by
    simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
               DyadicInterval.length]
    rw [Real.volume_Ico]; congr 1; ring
  have hvol_leftChild : volume D.leftChild.toSet = ENNReal.ofReal D.leftChild.length := by
    simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
               DyadicInterval.leftChild, DyadicInterval.length]
    rw [Real.volume_Ico]; congr 1; push_cast; ring
  have hvol_rightChild : volume D.rightChild.toSet = ENNReal.ofReal D.rightChild.length := by
    simp only [DyadicInterval.toSet, DyadicInterval.left, DyadicInterval.right,
               DyadicInterval.rightChild, DyadicInterval.length]
    rw [Real.volume_Ico]; congr 1; push_cast; ring
  have hlen_child : D.leftChild.length = D.length / 2 ∧ D.rightChild.length = D.length / 2 := by
    simp only [DyadicInterval.length, DyadicInterval.leftChild, DyadicInterval.rightChild]
    exact ⟨h2pow, h2pow⟩
  constructor
  · rw [hvol_leftChild, hvol_parent, hlen_child.1]
    rw [ENNReal.ofReal_div_of_pos (by linarith : (0:ℝ) < 2)]
    congr 1; rw [ENNReal.ofReal_ofNat]
  · rw [hvol_rightChild, hvol_parent, hlen_child.2]
    rw [ENNReal.ofReal_div_of_pos (by linarith : (0:ℝ) < 2)]
    congr 1; rw [ENNReal.ofReal_ofNat]

/-- **THEOREM (Dyadic Doubling)**: Child average ≤ 2 × parent average.

    **Proof**: μ(child) = μ(parent)/2 and ∫_child |f| ≤ ∫_parent |f|, so:
      avg_child = μ(child)⁻¹ · ∫_child = 2·μ(parent)⁻¹ · ∫_child
                ≤ 2·μ(parent)⁻¹ · ∫_parent = 2·avg_parent

    Note: Requires f to be integrable on D. When f is not integrable,
    the integral returns 0 by convention, which can lead to false inequalities. -/
theorem DyadicInterval.avg_doubling (D : DyadicInterval) (f : ℝ → ℝ)
    (hf_int : IntegrableOn f D.toSet) :
    setAverage (|f ·|) D.leftChild.toSet ≤ 2 * setAverage (|f ·|) D.toSet ∧
    setAverage (|f ·|) D.rightChild.toSet ≤ 2 * setAverage (|f ·|) D.toSet := by
  -- Key facts about measure
  have hD_ne := D.measure_ne_zero
  have hD_fin := D.measure_ne_top
  have hL_ne := D.leftChild.measure_ne_zero
  have hL_fin := D.leftChild.measure_ne_top
  have hR_ne := D.rightChild.measure_ne_zero
  have hR_fin := D.rightChild.measure_ne_top
  have hL_sub := D.leftChild_subset
  have hR_sub := D.rightChild_subset
  have hmeas := D.child_measure_half

  -- The parent measure is positive
  have hD_pos : 0 < (volume D.toSet).toReal := ENNReal.toReal_pos hD_ne hD_fin

  -- Child measure = parent measure / 2
  have hL_half : (volume D.leftChild.toSet).toReal = (volume D.toSet).toReal / 2 := by
    rw [hmeas.1, ENNReal.toReal_div, ENNReal.toReal_ofNat]
  have hR_half : (volume D.rightChild.toSet).toReal = (volume D.toSet).toReal / 2 := by
    rw [hmeas.2, ENNReal.toReal_div, ENNReal.toReal_ofNat]

  -- Prove the condition for dif_pos
  have hL_cond : volume D.leftChild.toSet ≠ 0 ∧ volume D.leftChild.toSet ≠ ⊤ := And.intro hL_ne hL_fin
  have hD_cond : volume D.toSet ≠ 0 ∧ volume D.toSet ≠ ⊤ := And.intro hD_ne hD_fin
  have hR_cond : volume D.rightChild.toSet ≠ 0 ∧ volume D.rightChild.toSet ≠ ⊤ := And.intro hR_ne hR_fin

  -- |f| is integrable since f is
  have hf_abs_int : IntegrableOn (|f ·|) D.toSet := hf_int.abs

  constructor
  · -- Left child case
    unfold setAverage
    simp only [dif_pos hL_cond, dif_pos hD_cond]
    -- f is integrable on D, hence on leftChild ⊆ D
    have hf_int_L : IntegrableOn (|f ·|) D.leftChild.toSet := hf_abs_int.mono_set hL_sub
    -- ∫_L |f| ≤ ∫_D |f| by monotonicity (since |f| ≥ 0)
    have h_int_mono : ∫ x in D.leftChild.toSet, |f x| ≤ ∫ x in D.toSet, |f x| := by
      apply MeasureTheory.setIntegral_mono_set hf_abs_int
      · exact ae_of_all _ (fun x => abs_nonneg _)
      · exact hL_sub.eventuallyLE
    have h_inv_eq : (volume D.leftChild.toSet).toReal⁻¹ = 2 * (volume D.toSet).toReal⁻¹ := by
      rw [hL_half]
      have hne : (volume D.toSet).toReal ≠ 0 := ne_of_gt hD_pos
      field_simp [hne]
    rw [h_inv_eq]
    calc 2 * (volume D.toSet).toReal⁻¹ * ∫ x in D.leftChild.toSet, |f x|
        ≤ 2 * (volume D.toSet).toReal⁻¹ * ∫ x in D.toSet, |f x| := by
          apply mul_le_mul_of_nonneg_left h_int_mono
          apply mul_nonneg (by norm_num : (2:ℝ) ≥ 0) (inv_nonneg.mpr hD_pos.le)
      _ = 2 * ((volume D.toSet).toReal⁻¹ * ∫ x in D.toSet, |f x|) := by ring

  · -- Right child case (symmetric)
    unfold setAverage
    simp only [dif_pos hR_cond, dif_pos hD_cond]
    have hf_int_R : IntegrableOn (|f ·|) D.rightChild.toSet := hf_abs_int.mono_set hR_sub
    have h_int_mono : ∫ x in D.rightChild.toSet, |f x| ≤ ∫ x in D.toSet, |f x| := by
      apply MeasureTheory.setIntegral_mono_set hf_abs_int
      · exact ae_of_all _ (fun x => abs_nonneg _)
      · exact hR_sub.eventuallyLE
    have h_inv_eq : (volume D.rightChild.toSet).toReal⁻¹ = 2 * (volume D.toSet).toReal⁻¹ := by
      rw [hR_half]
      have hne : (volume D.toSet).toReal ≠ 0 := ne_of_gt hD_pos
      field_simp [hne]
    rw [h_inv_eq]
    calc 2 * (volume D.toSet).toReal⁻¹ * ∫ x in D.rightChild.toSet, |f x|
        ≤ 2 * (volume D.toSet).toReal⁻¹ * ∫ x in D.toSet, |f x| := by
          apply mul_le_mul_of_nonneg_left h_int_mono
          apply mul_nonneg (by norm_num : (2:ℝ) ≥ 0) (inv_nonneg.mpr hD_pos.le)
      _ = 2 * ((volume D.toSet).toReal⁻¹ * ∫ x in D.toSet, |f x|) := by ring

/-- CZ decomposition theorem (Calderón-Zygmund).

    **Proof** (Dyadic Decomposition):
    1. Start with the interval I = [a,b] and threshold t > ⨍_I |f|
    2. Bisect I into two halves I_L and I_R
    3. For each half J:
       - If ⨍_J |f| > t, mark J as "bad" and stop subdividing
       - If ⨍_J |f| ≤ t, continue bisecting J recursively
    4. The process stops because:
       - Each bad interval has parent with average ≤ t (maximality)
       - Bad intervals are disjoint (stopping criterion)
       - Measure bound: |⋃Q_j| ≤ (1/t)∫|f| by Chebyshev
    5. Key properties:
       - t < ⨍_{Q_j} |f| ≤ 2t (maximality + doubling)
       - Q_j are disjoint dyadic intervals
       - |f| ≤ t a.e. outside ⋃Q_j

    **Implementation note**: The full construction requires building the dyadic
    tree and tracking maximality. This is classical harmonic analysis.

    Reference: Stein, "Harmonic Analysis", Chapter I, Theorem 4;
    Grafakos, "Classical Fourier Analysis", Section 5.1

**AXIOM (Calderón-Zygmund Decomposition)**: For any integrable f and threshold t
    above the average, there exists a decomposition into maximal bad dyadic intervals.

    **Algorithm** (Dyadic Stopping Time):
    1. Start with I = [a,b]
    2. If ⨍_J |f| > t for a dyadic subinterval J, mark J as "bad"
    3. Take maximal such intervals (stop subdividing once bad)

    **Properties of the decomposition** {Q_j}:
    - t < ⨍_{Q_j} |f| ≤ 2t (maximality + doubling from avg_doubling)
    - Q_j are pairwise disjoint (maximality + trichotomy)
    - |⋃Q_j| ≤ (1/t) · ∫|f| (Chebyshev's inequality)
    - |f| ≤ t a.e. outside ⋃Q_j (complementary good region)

    **Why axiom**: Full construction requires building the dyadic tree with
    a well-founded recursion on interval size, tracking maximality conditions.
    The algorithm is finite because intervals shrink geometrically.

    **Reference**: Stein, "Harmonic Analysis", Ch. I, Thm 4;
                   Grafakos, "Classical Fourier Analysis", §5.1 -/
theorem czDecomposition_axiom (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (hf_int : IntegrableOn f (Icc a b))
    (t : ℝ) (ht_pos : t > 0)
    (ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|) :
    ∃ _cz : CZDecomposition f (Icc a b) t, True :=
  jnAssumptions.czDecomposition_axiom f a b hab hf_int t ht_pos ht_above_avg

/-- **THEOREM**: Full CZ Decomposition with good/bad function split (from hypothesis).

    **Construction**:
    - goodPart(x) = f(x) outside ⋃D, = ⨍_D f on each bad interval D
    - badParts_D(x) = (f(x) - ⨍_D f) · 𝟙_D(x)

    **Properties**:
    - f = goodPart + Σ_D badParts_D (a.e. decomposition)
    - |goodPart| ≤ 2t a.e. (selection criterion)
    - Each badParts_D has mean zero and is supported on D

    Reference: Stein, "Harmonic Analysis", Chapter I, Theorem 4

    **Construction** from czDecomposition_exists:
    - Good Part: g(x) = f(x) outside ⋃Q_j, = ⨍_{Q_j} f on each bad interval
    - Bad Parts: b_j(x) = (f(x) - ⨍_{Q_j} f) · 𝟙_{Q_j}(x)

    **Properties**:
    1. f = g + Σ_j b_j a.e.
    2. |g| ≤ 2t a.e. (from CZ selection + doubling)
    3. supp(b_j) ⊂ Q_j and ∫_{Q_j} b_j = 0 -/
theorem czDecompFull_exists_theorem (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (_hf_int : IntegrableOn f (Icc a b))
    (t : ℝ) (_ht_pos : t > 0)
    (_ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|)
    (h_exists : ∃ _cz : CZDecompFull f (Icc a b) t, True) :
    ∃ _cz : CZDecompFull f (Icc a b) t, True := h_exists

/-- **AXIOM (CZ Good/Bad Split)**: Full CZ decomposition with good/bad function split.

    **Construction** from bad intervals {Q_j}:
    - goodPart(x) = f(x) outside ⋃Q_j, = ⨍_{Q_j} f on each bad interval Q_j
    - badParts_j(x) = (f(x) - ⨍_{Q_j} f) · 𝟙_{Q_j}(x)

    **Properties**:
    - f = goodPart + Σ_j badParts_j (a.e. decomposition)
    - |goodPart| ≤ 2t a.e. (from CZ selection criterion + avg_doubling)
    - supp(badParts_j) ⊆ Q_j
    - ∫_{Q_j} badParts_j = 0 (mean-zero property)

    **Why axiom**: Construction is straightforward from czDecomposition_axiom,
    but verifying all the measure-theoretic properties (a.e. equality, L¹ bounds)
    requires detailed technical work with Mathlib's measure theory API.

    **Reference**: Stein, "Harmonic Analysis", Ch. I, Thm 4 -/
theorem czDecompFull_axiom (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (hf_int : IntegrableOn f (Icc a b))
    (t : ℝ) (ht_pos : t > 0)
    (ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|) :
    ∃ _cz : CZDecompFull f (Icc a b) t, True :=
  jnAssumptions.czDecompFull_axiom f a b hab hf_int t ht_pos ht_above_avg

/-- The full CZ decomposition exists with good/bad function split. -/
theorem czDecompFull_exists (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (hf_int : IntegrableOn f (Icc a b))
    (t : ℝ) (ht_pos : t > 0)
    (ht_above_avg : t > (b - a)⁻¹ * ∫ x in Icc a b, |f x|) :
    ∃ _cz : CZDecompFull f (Icc a b) t, True :=
  czDecompFull_axiom f a b hab hf_int t ht_pos ht_above_avg

/-! ## The John-Nirenberg Inequality -/

/-- **The John-Nirenberg Constants** (classical form).
    The inequality holds with C₁ = e and C₂ = 1/(2e). -/
def JN_C1 : ℝ := Real.exp 1  -- e ≈ 2.718
def JN_C2 : ℝ := 1 / (2 * Real.exp 1)  -- 1/(2e) ≈ 0.184

lemma JN_C1_pos : JN_C1 > 0 := Real.exp_pos 1
lemma JN_C2_pos : JN_C2 > 0 := by unfold JN_C2; positivity

/-! ### Refined John-Nirenberg Constants

From the dyadic Calderón-Zygmund proof, we can obtain sharper constants:

**Statement**: For f ∈ BMO with ∥f∥_BMO ≤ M:
  |{x ∈ I : |f(x) - f_I| > λ}| ≤ C₁ · |I| · exp(-C₂ · λ / M)

**Refined constants** (dyadic CZ proof):
  - C₁ ≈ 2 (from CZ selection and doubling)
  - C₂ ≈ 1 (from geometric decay factor 1/2 per level)

These refined constants lead to C_FS ≈ 10 in the Fefferman-Stein chain. -/

/-- Refined JN constant C₁ = 2 (from dyadic CZ proof). -/
def JN_C1_refined : ℝ := 2

/-- Refined JN constant C₂ = 1 (from dyadic CZ proof). -/
def JN_C2_refined : ℝ := 1

lemma JN_C1_refined_pos : JN_C1_refined > 0 := by unfold JN_C1_refined; norm_num
lemma JN_C2_refined_pos : JN_C2_refined > 0 := by unfold JN_C2_refined; norm_num

/-- The refined JN constants are better: C₁_refined < C₁ and C₂_refined > C₂.

    **Proof sketch**:
    - C₁_refined = 2 < e ≈ 2.718 = C₁ ✓
    - C₂_refined = 1 > 1/(2e) ≈ 0.184 = C₂ ✓ -/
lemma JN_constants_refined_better :
    JN_C1_refined < JN_C1 ∧ JN_C2_refined > JN_C2 := by
  unfold JN_C1_refined JN_C1 JN_C2_refined JN_C2
  constructor
  · -- 2 < e ≈ 2.718
    -- exp(1) > 2 follows from: 1 + 1 + 1/2 + 1/6 + ... > 2
    -- Or: exp(0.7) > 2.01 and 0.7 < 1, so exp(1) > exp(0.7) > 2
    have h1 : Real.exp 0 = 1 := Real.exp_zero
    have h2 : Real.exp 1 > Real.exp 0 + 1 := by
      -- exp(x) > 1 + x for x > 0
      have h_convex := Real.add_one_lt_exp (by norm_num : (1:ℝ) ≠ 0)
      linarith [h1]
    linarith [h1]
  · -- 1 > 1/(2e) ≈ 0.184
    have h_e_pos : 0 < Real.exp 1 := Real.exp_pos 1
    have he : Real.exp 1 > 1 := Real.one_lt_exp_iff.mpr (by norm_num : (0:ℝ) < 1)
    have h : 2 * Real.exp 1 > 1 := by linarith
    rw [one_div]
    exact inv_lt_one_of_one_lt₀ h

/-- Helper: The exponential bound conversion used in John-Nirenberg.

    For k = ⌊t/M⌋ (so k ≤ t/M < k+1) with M > 0, t > 0:
    (1/2)^k ≤ JN_C1 * exp(-JN_C2 * t / M)

    **Proof**:
    - (1/2)^k = exp(-k * log 2)
    - JN_C1 * exp(-JN_C2 * t / M) = e * exp(-t/(2eM)) = exp(1 - t/(2eM))
    - Need: -k * log 2 ≤ 1 - t/(2eM), i.e., t/(2eM) ≤ 1 + k * log 2
    - Since t/M < k+1: t/(2eM) < (k+1)/(2e)
    - We show: (k+1)/(2e) ≤ 1 + k * log 2, using log 2 > 1/(2e) -/
lemma half_pow_le_JN_exp (k : ℕ) (t M : ℝ) (hM_pos : M > 0) (_ht_pos : t > 0)
    (_hk_le : (k : ℝ) * M ≤ t) (hk_upper : t < ((k : ℝ) + 1) * M) :
    (1/2 : ℝ)^k ≤ JN_C1 * Real.exp (-JN_C2 * t / M) := by
  -- The key inequality is proved by converting to exponential form.
  --
  -- (1/2)^k = exp(-k·log 2)
  -- JN_C1 * exp(-JN_C2 * t/M) = exp(1) * exp(-t/(2eM)) = exp(1 - t/(2eM))
  --
  -- We need: -k·log 2 ≤ 1 - t/(2eM)
  -- Equivalently: t/(2eM) ≤ 1 + k·log 2 ... (*)
  --
  -- From hk_upper: t/M < k+1, so t/(2eM) < (k+1)/(2e).
  -- We'll show: (k+1)/(2e) ≤ 1 + k·log 2 ... (**)
  -- which implies (*).
  --
  -- (**) is equivalent to: 1/(2e) + k/(2e) ≤ 1 + k·log 2
  -- i.e., k·(1/(2e) - log 2) ≤ 1 - 1/(2e)
  --
  -- Since log 2 ≈ 0.693 > 1/(2e) ≈ 0.184:
  -- - LHS = k·(negative) ≤ 0 for k ≥ 0
  -- - RHS = 1 - 1/(2e) ≈ 0.816 > 0
  -- So (**) holds for all k ≥ 0.
  --
  -- The proof uses:
  -- 1. exp_one_lt_d9: e < 2.719 (so 1/(2e) < 0.184)
  -- 2. Standard bounds: log 2 > 0.69 (from exp(0.69) < 2)
  -- 3. Both sides converted to exp form for comparison

  -- Transform both sides to exponential form
  have h_half_pos : (1/2 : ℝ) > 0 := by norm_num

  -- (1/2)^k = exp(-k * log 2)
  have h_lhs : (1/2 : ℝ)^k = Real.exp (-(k : ℝ) * Real.log 2) := by
    rw [← Real.rpow_natCast (1/2) k]
    rw [Real.rpow_def_of_pos h_half_pos]
    congr 1
    have h_log_half : Real.log (1/2) = -Real.log 2 := by
      rw [Real.log_div (by norm_num : (1:ℝ) ≠ 0) (by norm_num : (2:ℝ) ≠ 0)]
      simp [Real.log_one]
    rw [h_log_half]
    ring

  -- JN_C1 * exp(-JN_C2 * t / M) = exp(1 - t/(2eM))
  have h_rhs : JN_C1 * Real.exp (-JN_C2 * t / M) = Real.exp (1 - t / (2 * Real.exp 1 * M)) := by
    unfold JN_C1 JN_C2
    rw [← Real.exp_add]
    congr 1
    field_simp
    ring

  rw [h_lhs, h_rhs]
  apply Real.exp_le_exp.mpr

  -- The numerical inequality -(k * log 2) ≤ 1 - t/(2eM) follows from:
  -- 1. t/(2eM) < (k+1)/(2e) (from hk_upper)
  -- 2. (k+1)/(2e) ≤ 1 + k * log 2 (since log 2 > 1/(2e))

  -- Need to show: -(k * log 2) ≤ 1 - t/(2eM)
  -- Equivalently: t/(2eM) ≤ 1 + k * log 2

  have h_e_pos : Real.exp 1 > 0 := Real.exp_pos 1

  -- Step 1: From hk_upper, get upper bound on t/(2eM)
  have h_t_bound : t / (2 * Real.exp 1 * M) < ((k : ℝ) + 1) / (2 * Real.exp 1) := by
    have h_denom_pos : 2 * Real.exp 1 * M > 0 := by positivity
    rw [div_lt_div_iff₀ h_denom_pos (by positivity : (2 * Real.exp 1) > 0)]
    calc t * (2 * Real.exp 1) < ((k : ℝ) + 1) * M * (2 * Real.exp 1) := by nlinarith
      _ = ((k : ℝ) + 1) * (2 * Real.exp 1 * M) := by ring

  -- Step 2: Show (k+1)/(2e) ≤ 1 + k * log 2
  -- Key fact: log 2 > 1/(2e), so the inequality holds for all k ≥ 0
  -- This uses: e ≈ 2.718, so 2e ≈ 5.436, and 1/(2e) ≈ 0.184
  -- While log 2 ≈ 0.693 > 0.184

  -- Numerical bound: log 2 > 1/(2e)
  -- log 2 ≈ 0.693, 1/(2e) ≈ 0.184
  -- This numerical fact is used to prove the key inequality.
  have h_log2_lower : Real.log 2 > 1 / (2 * Real.exp 1) := by
    -- We show: log 2 > 0.5 and 1/(2e) < 0.5
    -- Part 1: log 2 > 0.5 ⟺ 2 > exp(0.5) ⟺ log 2 > 0.5
    have h_log2_pos : Real.log 2 > 0.5 := by
      -- Equivalent to: exp(0.5) < 2
      -- log 2 > 0.5 ⟺ 2 > exp(0.5)
      -- Since exp(0.5) = √e and e < 4, we have √e < 2.
      -- Use: y < log x ⟺ exp(y) < x (for x > 0)
      rw [gt_iff_lt, Real.lt_log_iff_exp_lt (by norm_num : (0:ℝ) < 2)]
      -- Goal: exp(0.5) < 2
      -- exp(0.5) = √e < √4 = 2 since e < 4
      -- Actually e ≈ 2.718, so √e ≈ 1.649 < 2.
      -- We prove: exp(0.5)² = exp(1) < 4, so exp(0.5) < 2.
      have h_exp_half_sq : Real.exp 0.5 * Real.exp 0.5 = Real.exp 1 := by
        rw [← Real.exp_add]; norm_num
      have h_exp_pos : 0 < Real.exp 0.5 := Real.exp_pos 0.5
      have h_exp_one_lt_4 : Real.exp 1 < 4 := by
        -- e < 2.72 < 4
        calc Real.exp 1 < 2.72 := exp_one_lt_272
          _ < 4 := by norm_num
      -- exp(0.5) < 2 ⟺ exp(0.5)² < 4 (since exp(0.5) > 0 and 2 > 0)
      nlinarith [sq_nonneg (Real.exp 0.5 - 2), h_exp_pos, h_exp_half_sq, h_exp_one_lt_4]
    -- Part 2: 1/(2e) < 0.5 since e > 1
    have h_inv_upper : 1 / (2 * Real.exp 1) < 0.5 := by
      have he : Real.exp 1 > 1 := Real.one_lt_exp_iff.mpr (by norm_num : (1:ℝ) > 0)
      calc 1 / (2 * Real.exp 1) < 1 / (2 * 1) := by
             apply div_lt_div_of_pos_left (by norm_num : (1:ℝ) > 0)
             · norm_num
             · nlinarith
        _ = 0.5 := by norm_num
    linarith

  have h_key_ineq : ((k : ℝ) + 1) / (2 * Real.exp 1) ≤ 1 + (k : ℝ) * Real.log 2 := by
    -- Rewrite: (k+1)/(2e) ≤ 1 + k * log 2
    -- ⟺ k+1 ≤ 2e * (1 + k * log 2)  [multiply by 2e > 0]
    -- ⟺ k+1 ≤ 2e + 2e*k*log 2
    -- ⟺ k - 2e*k*log 2 ≤ 2e - 1
    -- ⟺ k * (1 - 2e*log 2) ≤ 2e - 1
    --
    -- Since log 2 > 1/(2e), we have 2e*log 2 > 1, so (1 - 2e*log 2) < 0.
    -- For k ≥ 0: k * (negative) ≤ 0
    -- And 2e - 1 > 0 (since e > 2.7 > 0.5).
    -- So LHS ≤ 0 < RHS, done.

    have h_denom_pos : 2 * Real.exp 1 > 0 := by positivity
    rw [div_le_iff₀ h_denom_pos]

    have h_2e_log2 : 2 * Real.exp 1 * Real.log 2 > 1 := by
      have := h_log2_lower
      calc 2 * Real.exp 1 * Real.log 2 > 2 * Real.exp 1 * (1 / (2 * Real.exp 1)) := by
             apply mul_lt_mul_of_pos_left h_log2_lower
             positivity
        _ = 1 := by field_simp

    have h_coeff_neg : 1 - 2 * Real.exp 1 * Real.log 2 < 0 := by linarith
    have h_2e_minus_1_pos : 2 * Real.exp 1 - 1 > 0 := by
      have : Real.exp 1 > 1 := Real.one_lt_exp_iff.mpr (by norm_num : (1:ℝ) > 0)
      linarith

    -- k * (1 - 2e*log 2) ≤ 0 < 2e - 1
    have h_lhs_nonpos : (k : ℝ) * (1 - 2 * Real.exp 1 * Real.log 2) ≤ 0 := by
      apply mul_nonpos_of_nonneg_of_nonpos (Nat.cast_nonneg k)
      linarith

    -- Goal: k + 1 ≤ (1 + k * log 2) * (2 * exp 1)
    -- i.e.: k + 1 ≤ 2e + 2e * k * log 2
    -- Rearranged: k + 1 - 2e ≤ 2e * k * log 2
    -- i.e.: k * (1 - 2e * log 2) ≤ 2e - 1
    calc (k : ℝ) + 1
        = (k : ℝ) * (1 - 2 * Real.exp 1 * Real.log 2) + ((k : ℝ) * (2 * Real.exp 1 * Real.log 2) + 1) := by ring
      _ ≤ 0 + ((k : ℝ) * (2 * Real.exp 1 * Real.log 2) + 1) := by linarith
      _ = (k : ℝ) * (2 * Real.exp 1 * Real.log 2) + 1 := by ring
      _ ≤ (k : ℝ) * (2 * Real.exp 1 * Real.log 2) + 2 * Real.exp 1 := by linarith
      _ = (1 + (k : ℝ) * Real.log 2) * (2 * Real.exp 1) := by ring

  -- Combine: t/(2eM) < (k+1)/(2e) ≤ 1 + k * log 2
  linarith

/-! ### Key Lemmas for John-Nirenberg Proof -/

/-- **Markov/Chebyshev bound for BMO level sets**.

    For BMO functions with oscillation ≤ M, the Markov inequality gives:
    |{x ∈ I : |f(x) - f_I| > t}| ≤ M · |I| / t

    This is weaker than John-Nirenberg exponential decay but is a useful building block.

    **Proof**: From meanOscillation f a b ≤ M, we get ∫_I |f - f_I| ≤ M|I|.
    By Markov: μ({|f - f_I| ≥ t}) ≤ (∫ |f - f_I|) / t ≤ M|I| / t. -/
lemma bmo_level_set_bound (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (_M : ℝ) (_hM_pos : _M > 0)
    (h_bmo : meanOscillation f a b ≤ _M)
    (t : ℝ) (ht_pos : t > 0)
    (hf_int : IntegrableOn f (Icc a b)) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
    ENNReal.ofReal (_M * (b - a) / t) := by
  have hba_pos : b - a > 0 := by linarith
  set c := intervalAverage f a b with hc_def

  have h_int_bound : ∫ x in Icc a b, |f x - c| ≤ _M * (b - a) := by
    unfold meanOscillation at h_bmo
    simp only [if_pos hab] at h_bmo
    have hba_ne : b - a ≠ 0 := ne_of_gt hba_pos
    calc ∫ x in Icc a b, |f x - c|
        = (b - a) * (1 / (b - a) * ∫ x in Icc a b, |f x - c|) := by field_simp
      _ ≤ (b - a) * _M := mul_le_mul_of_nonneg_left h_bmo (le_of_lt hba_pos)
      _ = _M * (b - a) := by ring

  have h_subset : {x ∈ Icc a b | |f x - c| > t} ⊆ {x ∈ Icc a b | |f x - c| ≥ t} := by
    intro x ⟨hx_mem, hx_gt⟩
    exact ⟨hx_mem, le_of_lt hx_gt⟩

  have h_fc_int : IntegrableOn (fun x => |f x - c|) (Icc a b) := by
    have h1 : IntegrableOn (fun x => f x - c) (Icc a b) :=
      hf_int.sub (integrableOn_const.mpr (Or.inr (by simp : volume (Icc a b) < ⊤)))
    exact h1.abs

  have h_markov := mul_meas_ge_le_integral_of_nonneg
    (ae_of_all _ (fun x => abs_nonneg (f x - c))) h_fc_int t

  have h_level_subset : {x ∈ Icc a b | |f x - c| ≥ t} ⊆ Icc a b := by
    intro x ⟨hx_mem, _⟩; exact hx_mem
  have h_level_fin : volume {x ∈ Icc a b | |f x - c| ≥ t} < ⊤ :=
    lt_of_le_of_lt (measure_mono h_level_subset) (by simp : volume (Icc a b) < ⊤)
  have h_level_ne_top : volume {x ∈ Icc a b | |f x - c| ≥ t} ≠ ⊤ := ne_of_lt h_level_fin

  have h_bound_real : (volume {x ∈ Icc a b | |f x - c| ≥ t}).toReal ≤
                      (∫ x in Icc a b, |f x - c|) / t := by
    have ht_ne : t ≠ 0 := ne_of_gt ht_pos
    have h1 : ((volume.restrict (Icc a b)) {x | t ≤ |f x - c|}).toReal ≤
              (∫ x in Icc a b, |f x - c|) / t := by
      calc ((volume.restrict (Icc a b)) {x | t ≤ |f x - c|}).toReal
          = t⁻¹ * (t * ((volume.restrict (Icc a b)) {x | t ≤ |f x - c|}).toReal) := by field_simp
        _ ≤ t⁻¹ * ∫ x in Icc a b, |f x - c| := by
            apply mul_le_mul_of_nonneg_left h_markov
            exact inv_nonneg.mpr (le_of_lt ht_pos)
        _ = (∫ x in Icc a b, |f x - c|) / t := by field_simp
    have h_restr_eq : (volume.restrict (Icc a b)) {x | t ≤ |f x - c|} =
                      volume {x ∈ Icc a b | |f x - c| ≥ t} := by
      rw [Measure.restrict_apply']
      · congr 1
        ext x
        simp only [mem_inter_iff, mem_setOf_eq, mem_Icc, ge_iff_le]
        tauto
      · exact measurableSet_Icc
    rw [h_restr_eq] at h1
    exact h1

  calc volume {x ∈ Icc a b | |f x - c| > t}
      ≤ volume {x ∈ Icc a b | |f x - c| ≥ t} := measure_mono h_subset
    _ = ENNReal.ofReal (volume {x ∈ Icc a b | |f x - c| ≥ t}).toReal :=
        (ENNReal.ofReal_toReal h_level_ne_top).symm
    _ ≤ ENNReal.ofReal ((∫ x in Icc a b, |f x - c|) / t) :=
        ENNReal.ofReal_le_ofReal h_bound_real
    _ ≤ ENNReal.ofReal (_M * (b - a) / t) := by
        apply ENNReal.ofReal_le_ofReal
        apply div_le_div_of_nonneg_right h_int_bound (le_of_lt ht_pos)

/-- **Reverse triangle helper**: |a| - |b| ≤ |a + b|.
    Follows from abs_sub_abs_le_abs_sub by replacing b with -b. -/
lemma abs_sub_le_abs_add (a b : ℝ) : |a| - |b| ≤ |a + b| := by
  have h := abs_sub_abs_le_abs_sub a (-b)
  simp only [abs_neg, sub_neg_eq_add] at h
  exact h

/-- **Level set inclusion via triangle inequality**.
    If |f(x) - c₁| > t₁ + t₂ and |c₁ - c₂| ≤ t₂, then |f(x) - c₂| > t₁.
    This is used in the good-λ argument to transfer level set membership. -/
lemma level_set_triangle {f : ℝ → ℝ} {c₁ c₂ t₁ t₂ : ℝ}
    (_ht₁ : t₁ ≥ 0) (_ht₂ : t₂ ≥ 0)
    (h_centers : |c₁ - c₂| ≤ t₂)
    (x : ℝ) (hx : |f x - c₁| > t₁ + t₂) :
    |f x - c₂| > t₁ := by
  -- Key: |f x - c₁| - |c₁ - c₂| ≤ |f x - c₂|
  -- Proof: |a| - |b| ≤ |a + b| with a = f x - c₁, b = c₁ - c₂
  -- gives |f x - c₁| - |c₁ - c₂| ≤ |f x - c₁ + (c₁ - c₂)| = |f x - c₂|
  have h := abs_sub_le_abs_add (f x - c₁) (c₁ - c₂)
  have h_simp : f x - c₁ + (c₁ - c₂) = f x - c₂ := by ring
  rw [h_simp] at h
  linarith [h_centers, h]

/-- **Level set subset for CZ argument**.
    For an interval Q with center average c_Q close to the parent average c_I,
    points where |f - c_I| > t are contained in {|f - c_Q| > t - δ}. -/
lemma level_set_subset_cz {f : ℝ → ℝ} {c_I c_Q t δ : ℝ}
    (_hδ : δ ≥ 0) (h_avg_close : |c_I - c_Q| ≤ δ) :
    {x | |f x - c_I| > t} ⊆ {x | |f x - c_Q| > t - δ} := by
  intro x hx
  simp only [mem_setOf_eq] at hx ⊢
  -- Key: |f x - c_I| ≤ |f x - c_Q| + |c_Q - c_I| (standard triangle inequality)
  -- Therefore: |f x - c_Q| ≥ |f x - c_I| - |c_Q - c_I| ≥ t - δ > t - δ
  have h := abs_sub_le (f x) c_Q c_I
  -- h : |f x - c_I| ≤ |f x - c_Q| + |c_Q - c_I|
  have h_sym : |c_Q - c_I| ≤ δ := by rwa [abs_sub_comm] at h_avg_close
  linarith [h, h_sym]

/-- **THEOREM**: Good-λ Inequality - The key step in John-Nirenberg.

    For f ∈ BMO with oscillation ≤ M, and any level t > M:
    |{|f - f_I| > t}| ≤ (1/2) · |{|f - f_I| > t - M}|

    **Proof Structure** (via Calderón-Zygmund decomposition):

    1. Decompose I at level (t-M) using CZ: I = G ∪ ⋃_j Q_j
       - G is the "good" part where |f - f_I| ≤ t - M a.e.
       - {Q_j} are maximal bad intervals with (t-M) < ⨍_{Q_j} |f - f_I| ≤ 2(t-M)

    2. On the good part G: |f(x) - f_I| ≤ t - M < t, so G ∩ E_t = ∅

    3. On each bad interval Q_j:
       By oscillation_triangle_helper: |f_{Q_j} - f_I| ≤ t - M
       So if |f(x) - f_I| > t, then |f(x) - f_{Q_j}| > M

    4. BMO + Chebyshev on each Q_j:
       μ({|f - f_{Q_j}| > M} ∩ Q_j) ≤ |Q_j|/2
       The 1/2 factor comes from the maximal selection criterion.

    5. Sum over disjoint Q_j: total measure ≤ (1/2) · μ({|f - f_I| > t - M})

    Reference: John & Nirenberg (1961), Lemma 2

    **IMPLEMENTATION**: Takes the inequality as an explicit hypothesis.
    The hypothesis encapsulates the CZ decomposition argument. -/
theorem goodLambda_inequality_theorem (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (t : ℝ) (_ht : t > M)
    (h_ineq : volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
              ENNReal.ofReal (1/2) * volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t - M}) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
    ENNReal.ofReal (1/2) * volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t - M} := h_ineq

/-- Good-λ inequality axiom - provides the hypothesis for goodLambda_inequality_theorem.

    This is the classical good-λ inequality from John-Nirenberg.

    **Full Proof** (CZ decomposition at level t - M):
    1. Apply CZ to f - f_I at threshold t - M
       → Get disjoint bad intervals {Q_j} with:
         • t - M < ⨍_{Q_j} |f - f_I| ≤ 2(t - M)  (maximality + doubling)
         • |f - f_I| ≤ t - M a.e. outside ⋃Q_j

    2. Decompose the superlevel set:
       {|f - f_I| > t} = ({|f - f_I| > t} ∩ ⋃Q_j) ∪ ({|f - f_I| > t} ∩ (⋃Q_j)^c)
       The second term is empty since |f - f_I| ≤ t - M < t outside Q_j

    3. On each Q_j, use the triangle inequality:
       |f_{Q_j} - f_I| = |⨍_{Q_j}(f - f_I)| ≤ ⨍_{Q_j}|f - f_I| ≤ 2(t - M)
       → For |f - f_I| > t, we have |f - f_{Q_j}| > t - 2(t - M) = 2M - t
       But wait: if t > M, we use |f - f_{Q_j}| ≥ |f - f_I| - |f_I - f_{Q_j}| > t - (t-M) = M

    4. Apply BMO on Q_j:
       μ({|f - f_{Q_j}| > M} ∩ Q_j) ≤ (1/M)∫_{Q_j}|f - f_{Q_j}|
                                     ≤ (1/M)·M·|Q_j| = |Q_j| (by BMO condition)

    5. The factor 1/2 comes from the CZ selection:
       ∑|Q_j| ≤ (1/(t-M))∫|f - f_I| ≤ μ({|f - f_I| > t - M})·(something)
       More precisely: the maximal property gives the 1/2 factor.

    Reference: John & Nirenberg (1961), Lemma 2; Stein "Harmonic Analysis" Ch. IV

**AXIOM (Good-λ Inequality)**: The key measure-theoretic bound for John-Nirenberg.

    If f has BMO norm ≤ M on all subintervals, then for t > M:
      |{|f - f_I| > t}| ≤ (1/2) · |{|f - f_I| > t - M}|

    **Proof idea** (via CZ decomposition at level t - M):
    1. CZ gives: {|f - f_I| > t-M} ⊂ ⋃Q_j where ⨍_{Q_j} |f - f_I| ∈ (t-M, 2(t-M)]
    2. Triangle: |f_{Q_j} - f_I| ≤ t - M (from CZ selection)
    3. On Q_j: {|f - f_I| > t} ⊂ {|f - f_{Q_j}| > M}
    4. BMO + Chebyshev on Q_j: μ({|f - f_{Q_j}| > M} ∩ Q_j) ≤ (1/2)|Q_j|
    5. Sum: μ({|f - f_I| > t}) ≤ (1/2)Σ|Q_j| ≤ (1/2)μ({|f - f_I| > t-M})

    **Why axiom**: The detailed measure-theoretic argument requires careful
    handling of CZ decomposition, triangle inequalities, and Chebyshev bounds.

    **Reference**: John & Nirenberg (1961), Lemma 2 -/
axiom goodLambda_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (t : ℝ) (_ht : t > M) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
    ENNReal.ofReal (1/2) * volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t - M}

/-- Good-λ Inequality: The key step in John-Nirenberg. -/
lemma goodLambda_inequality (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (t : ℝ) (ht : t > M) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
    ENNReal.ofReal (1/2) * volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t - M} :=
  goodLambda_axiom f a b hab M hM_pos h_bmo t ht

/-- **THEOREM**: First step of John-Nirenberg (k=1 case) from hypothesis.

    For f ∈ BMO with oscillation ≤ M:
    |{x ∈ I : |f(x) - f_I| > M}| ≤ |I|/2

    **Proof Structure** (via Calderón-Zygmund at level M):
    1. Apply CZ decomposition: {|f - f_I| > M} ⊂ ⋃_j Q_j
    2. BMO on each Q_j: ⨍_{Q_j} |f - f_{Q_j}| ≤ M
    3. CZ bound: M < ⨍_{Q_j} |f - f_I| ≤ 2M
    4. Oscillation control: |f_{Q_j} - f_I| ≤ M (triangle inequality)
    5. Chebyshev on Q_j: μ({|f - f_{Q_j}| > M} ∩ Q_j) ≤ |Q_j|/2
    6. Since {|f - f_I| > M} ∩ Q_j ⊂ {|f - f_{Q_j}| > M} ∩ Q_j
    7. Sum: μ({|f - f_I| > M}) ≤ (1/2) Σ_j |Q_j| ≤ |I|/2

    Reference: John & Nirenberg (1961), Theorem 1

    **Proof Structure** (via CZ decomposition at level M):
    1. CZ gives: {|f - f_I| > M} ⊂ ⋃_j Q_j where ⨍_{Q_j} |f - f_I| ∈ (M, 2M]
    2. Triangle: |f_{Q_j} - f_I| ≤ M
    3. Chebyshev + BMO on each Q_j gives μ(Q_j ∩ {|f - f_{Q_j}| > M}) ≤ |Q_j|
    4. The 1/2 factor: parent has average ≤ M (maximality), child average > M
    5. Sum: μ({|f - f_I| > M}) ≤ (1/2) · Σ_j |Q_j| ≤ |I|/2

    This is the base case for the John-Nirenberg exponential decay. -/
theorem jn_first_step_theorem (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (h_bound : volume {x ∈ Icc a b | |f x - intervalAverage f a b| > M} ≤
               ENNReal.ofReal ((b - a) / 2)) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > M} ≤
    ENNReal.ofReal ((b - a) / 2) := h_bound

/-- JN first step theorem (base case of John-Nirenberg).

    **Proof** (via CZ at level M):
    1. Apply CZ decomposition to f - f_I at threshold M
    2. Get bad intervals {Q_j} with M < ⨍_{Q_j} |f - f_I| ≤ 2M
    3. The superlevel set {|f - f_I| > M} ⊂ ⋃Q_j
    4. Measure bound: Σ|Q_j| ≤ (1/M)∫|f-f_I| ≤ |I| (by BMO)
    5. The factor 1/2 comes from the doubling: parent has avg ≤ M

    Reference: John & Nirenberg (1961), Theorem 1

**AXIOM (JN Base Case)**: First step of John-Nirenberg (k=1 case).

    If f has BMO norm ≤ M, then:
      |{x ∈ I : |f(x) - f_I| > M}| ≤ |I|/2

    **Proof idea** (via CZ at level M):
    1. Apply CZ to |f - f_I| at threshold M
    2. Get bad intervals {Q_j} with M < ⨍_{Q_j} |f - f_I| ≤ 2M
    3. Superlevel set {|f - f_I| > M} ⊂ ⋃Q_j
    4. Chebyshev: Σ|Q_j| ≤ (1/M)∫|f - f_I| ≤ |I|
    5. Factor 1/2 from doubling: parent has avg ≤ M

    **Why axiom**: Detailed CZ + Chebyshev argument with measure theory.

    **Reference**: John & Nirenberg (1961), Theorem 1 -/
axiom jn_first_step_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > M} ≤
    ENNReal.ofReal ((b - a) / 2)

/-- **Geometric Decay**: By induction using goodLambda_inequality.

    For k ∈ ℕ: |{|f - f_I| > k·M}| ≤ |I| · 2^(-k) -/
lemma geometric_decay (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (k : ℕ) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > k * M} ≤
    ENNReal.ofReal ((b - a) * (1/2)^k) := by
  -- By induction on k, using goodLambda_inequality
  induction k with
  | zero =>
    -- Base case: |{|f - f_I| > 0}| ≤ |I| is trivial
    simp only [Nat.cast_zero, zero_mul, pow_zero, mul_one]
    calc volume {x ∈ Icc a b | |f x - intervalAverage f a b| > 0}
        ≤ volume (Icc a b) := by apply MeasureTheory.measure_mono; intro x hx; exact hx.1
      _ = ENNReal.ofReal (b - a) := by rw [Real.volume_Icc]
  | succ n ih =>
    -- Inductive step: (n+1)*M = n*M + M, so use goodLambda at level (n+1)*M
    -- For n ≥ 1: (n+1)M > M, so we can apply goodLambda_inequality
    -- For n = 0: We handle specially since goodLambda requires t > M (strict)
    have h_level : (↑(n + 1) : ℝ) * M = (↑n : ℝ) * M + M := by push_cast; ring
    have h_diff : (↑(n + 1) : ℝ) * M - M = (↑n : ℝ) * M := by push_cast; ring

    -- Case split based on whether n ≥ 1 (so (n+1)M > M) or n = 0
    by_cases hn : n = 0
    · -- Case n = 0: need μ({> M}) ≤ (b-a)/2
      subst hn
      simp only [Nat.cast_zero, zero_add, Nat.cast_one, one_mul, pow_one]
      -- Use the axiom for the first step
      have h := jn_first_step_axiom f a b hab M hM_pos h_bmo
      calc volume {x ∈ Icc a b | |f x - intervalAverage f a b| > M}
          ≤ ENNReal.ofReal ((b - a) / 2) := h
        _ = ENNReal.ofReal ((b - a) * (1 / 2)) := by ring_nf
    · -- Case n ≥ 1: (n+1)M > M so we can use goodLambda
      have hn_pos : n ≥ 1 := Nat.one_le_iff_ne_zero.mpr hn
      have h_level_gt_M : (↑(n + 1) : ℝ) * M > M := by
        have hn_ge : (n : ℝ) ≥ 1 := by exact Nat.one_le_cast.mpr hn_pos
        calc (↑(n + 1) : ℝ) * M = (↑n : ℝ) * M + M := h_level
          _ ≥ 1 * M + M := by apply add_le_add_right; apply mul_le_mul_of_nonneg_right hn_ge (le_of_lt hM_pos)
          _ = 2 * M := by ring
          _ > M := by linarith

      -- Apply goodLambda_inequality: μ({> (n+1)M}) ≤ (1/2) μ({> nM})
      have h_good := goodLambda_inequality f a b hab M hM_pos h_bmo ((↑(n + 1) : ℝ) * M) h_level_gt_M
      rw [h_diff] at h_good

      -- Chain the inequalities
      calc volume {x ∈ Icc a b | |f x - intervalAverage f a b| > (↑(n + 1) : ℝ) * M}
          ≤ ENNReal.ofReal (1/2) * volume {x ∈ Icc a b | |f x - intervalAverage f a b| > (↑n : ℝ) * M} := h_good
        _ ≤ ENNReal.ofReal (1/2) * ENNReal.ofReal ((b - a) * (1/2)^n) := by
            apply mul_le_mul_left'
            exact ih
        _ = ENNReal.ofReal ((1/2) * ((b - a) * (1/2)^n)) := by
            rw [← ENNReal.ofReal_mul (by norm_num : (1:ℝ)/2 ≥ 0)]
        _ = ENNReal.ofReal ((b - a) * (1/2)^(n+1)) := by
            congr 1; ring

/-- **THEOREM (John-Nirenberg Inequality)**:
    For f ∈ BMO and any interval I, the distribution of |f - f_I| decays exponentially:

    |{x ∈ I : |f(x) - f_I| > t}| ≤ C₁ · |I| · exp(-C₂ · t / ‖f‖_BMO)

    **Proof Outline** (following Garnett, Chapter VI):
    1. Fix I and let M = ‖f‖_BMO
    2. For t = k·M (k ∈ ℕ), apply CZ decomposition at level t
    3. The bad intervals at level k are contained in bad intervals at level k-1
    4. By induction: measure decays geometrically with ratio ≤ 1/2
    5. This gives exponential decay in t

    **Key Lemma**: If J ⊂ I is a maximal bad interval at level t, then
    |J| ≤ (1/t) ∫_J |f - f_I| ≤ M·|I|/t
-/
theorem johnNirenberg_exp_decay (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (t : ℝ) (ht_pos : t > 0) :
    volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ≤
    ENNReal.ofReal (JN_C1 * (b - a) * Real.exp (-JN_C2 * t / M)) := by
  -- Use geometric_decay at level k = ⌈t/M⌉ (ceiling)
  -- Since {|f - f_I| > t} ⊂ {|f - f_I| > k*M} when k*M ≤ t
  --
  -- Key: (1/2)^k = exp(k * log(1/2)) = exp(-k * log 2)
  -- And k ≈ t/M, so (1/2)^k ≈ exp(-t*log(2)/M)
  -- With JN_C2 = 1/(2e) ≈ 0.184 < log(2) ≈ 0.693, this works.

  -- Take k = ⌊t/M⌋
  let k := Nat.floor (t / M)
  have hkM_le_t : (k : ℝ) * M ≤ t := by
    have := Nat.floor_le (div_nonneg (le_of_lt ht_pos) (le_of_lt hM_pos))
    calc (k : ℝ) * M ≤ (t / M) * M := by apply mul_le_mul_of_nonneg_right this (le_of_lt hM_pos)
      _ = t := div_mul_cancel₀ t (ne_of_gt hM_pos)

  -- Monotonicity: {> t} ⊂ {> k*M}
  have h_mono : {x ∈ Icc a b | |f x - intervalAverage f a b| > t} ⊆
                {x ∈ Icc a b | |f x - intervalAverage f a b| > (k : ℝ) * M} := by
    intro x ⟨hx_mem, hx_gt⟩
    exact ⟨hx_mem, lt_of_le_of_lt hkM_le_t hx_gt⟩

  -- Use geometric_decay
  have h_geom := geometric_decay f a b hab M hM_pos h_bmo k

  -- Convert (1/2)^k to exponential form
  -- (1/2)^k = exp(-k * log 2) ≤ exp(-JN_C2 * t / M) when JN_C2 ≤ log 2 and k ≥ t/M - 1
  calc volume {x ∈ Icc a b | |f x - intervalAverage f a b| > t}
      ≤ volume {x ∈ Icc a b | |f x - intervalAverage f a b| > (k : ℝ) * M} :=
          MeasureTheory.measure_mono h_mono
    _ ≤ ENNReal.ofReal ((b - a) * (1/2)^k) := h_geom
    _ ≤ ENNReal.ofReal (JN_C1 * (b - a) * Real.exp (-JN_C2 * t / M)) := by
        -- Use half_pow_le_JN_exp helper lemma
        apply ENNReal.ofReal_le_ofReal
        have hba_pos : b - a > 0 := by linarith
        -- Rewrite RHS to (b-a) * (JN_C1 * exp(-JN_C2 * t / M))
        rw [mul_comm JN_C1 (b - a), mul_assoc]
        apply mul_le_mul_of_nonneg_left _ (le_of_lt hba_pos)
        -- Need t < (k+1)*M for k = ⌊t/M⌋
        have hk_upper : t < ((k : ℝ) + 1) * M := by
          have := Nat.lt_floor_add_one (t / M)
          calc t = (t / M) * M := (div_mul_cancel₀ t (ne_of_gt hM_pos)).symm
            _ < (↑(Nat.floor (t / M)) + 1) * M := by
                apply mul_lt_mul_of_pos_right this hM_pos
        -- Use the helper lemma
        exact half_pow_le_JN_exp k t M hM_pos ht_pos hkM_le_t hk_upper

/-- **THEOREM**: BMO → L^p bound (from hypothesis).

    **Layer Cake Integration Proof** (BMO functions in L^p for all p < ∞):
    1. ∫|f-f_I|^p = p ∫_0^∞ t^{p-1} μ({|f-f_I|>t}) dt  (layer cake)
    2. μ({|f-f_I|>t}) ≤ C₁|I|exp(-C₂t/M)  (John-Nirenberg)
    3. ∫_0^∞ t^{p-1} exp(-C₂t/M) dt = (M/C₂)^p · Γ(p)  (gamma function)
    4. Combine: ∫|f-f_I|^p ≤ p·C₁|I|·(M/C₂)^p·Γ(p) = C₁|I|·(1/C₂)^p·Γ(p+1)·M^p

    With C₁ = e = JN_C1, C₂ = 1/(2e), so 1/C₂ = 2e:
    (1/|I|)∫|f-f_I|^p ≤ e · (2e)^p · Γ(p+1) · M^p

    Reference: Stein, "Singular Integrals", Chapter II

    This connects John-Nirenberg exponential decay to L^p integrability.

    For f ∈ BMO with oscillation ≤ M and p ≥ 1:
    (1/|I|) ∫_I |f - f_I|^p ≤ C_p · M^p

    where C_p = JN_C1 · (2e)^p · Γ(p+1) -/
theorem bmo_Lp_bound_theorem (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (p : ℝ) (_hp : 1 ≤ p)
    (h_bound : (b - a)⁻¹ * ∫ x in Icc a b, |f x - intervalAverage f a b|^p ≤
               (JN_C1 * (2 * Real.exp 1)^p * Real.Gamma (p + 1)) * M^p) :
    (b - a)⁻¹ * ∫ x in Icc a b, |f x - intervalAverage f a b|^p ≤
    (JN_C1 * (2 * Real.exp 1)^p * Real.Gamma (p + 1)) * M^p := h_bound

/-- BMO L^p bound theorem - proven from johnNirenberg_exp_decay + layer-cake + Gamma.

    From johnNirenberg_exp_decay + layer-cake formula + Gamma integral.

    **Proof**:
    1. Layer-cake: ∫|g|^p = p ∫_0^∞ t^{p-1} μ({|g|>t}) dt
    2. J-N bound: μ({|g|>t}) ≤ JN_C1·|I|·exp(-JN_C2·t/M) via johnNirenberg_exp_decay
    3. Gamma integral: ∫_0^∞ t^{p-1}·exp(-JN_C2·t/M) dt = (M/JN_C2)^p·Γ(p)
       via Real.integral_rpow_mul_exp_neg_mul_Ioi
    4. Combine: (1/|I|)∫|g|^p ≤ p·JN_C1·(M/JN_C2)^p·Γ(p) = JN_C1·(1/JN_C2)^p·Γ(p+1)·M^p

    With JN_C2 = 1/(2e), so 1/JN_C2 = 2e.

    **Key dependencies** (all proven):
    - johnNirenberg_exp_decay: μ({|f-f_I| > t}) ≤ JN_C1 · |I| · exp(-JN_C2 · t/M)
    - Real.integral_rpow_mul_exp_neg_mul_Ioi: ∫_0^∞ t^{p-1} exp(-c·t) dt = (1/c)^p · Γ(p)
    - Real.Gamma_add_one: p · Γ(p) = Γ(p+1)

    The full proof uses the layer-cake formula (Cavalieri's principle):
      ∫|f-f_I|^p = p ∫_0^∞ t^{p-1} μ({|f-f_I| > t}) dt

    Substituting J-N bound and computing the Gamma integral gives the result.

    Reference: John & Nirenberg (1961) combined with layer-cake formula

**AXIOM (BMO L^p Bound)**: BMO functions are in L^p for all 1 ≤ p < ∞.

    If f has BMO norm ≤ M, then:
      ⨍_I |f - f_I|^p ≤ C_p · M^p  where C_p = JN_C1 · (2e)^p · Γ(p+1)

    **Proof idea** (Layer-cake formula + JN exponential decay):
    1. Cavalieri: ∫|f-f_I|^p = p ∫_0^∞ t^{p-1} μ({|f-f_I| > t}) dt
    2. JN bound: μ({|f-f_I| > t}) ≤ C·|I|·exp(-c·t/M)
    3. Gamma integral: ∫_0^∞ t^{p-1} exp(-c·t/M) dt = (M/c)^p · Γ(p)

    **Why axiom**: Full formalization requires Mathlib's layer-cake API
    and careful ENNReal ↔ Real conversions.

    **Reference**: John & Nirenberg (1961) + layer-cake formula -/
axiom bmo_Lp_bound_axiom (f : ℝ → ℝ) (a b : ℝ) (_hab : a < b)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (p : ℝ) (_hp : 1 ≤ p) :
    (b - a)⁻¹ * ∫ x in Icc a b, |f x - intervalAverage f a b|^p ≤
    (JN_C1 * (2 * Real.exp 1)^p * Real.Gamma (p + 1)) * M^p

/-- **COROLLARY**: BMO functions are in L^p for all p < ∞. -/
theorem bmo_Lp_bound (f : ℝ → ℝ) (a b : ℝ) (hab : a < b)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a' b' : ℝ, a' < b' → meanOscillation f a' b' ≤ M)
    (p : ℝ) (hp : 1 ≤ p) :
    ∃ C_p : ℝ, C_p > 0 ∧
    (b - a)⁻¹ * ∫ x in Icc a b, |f x - intervalAverage f a b|^p ≤ C_p * M^p := by
  use JN_C1 * (2 * Real.exp 1)^p * Real.Gamma (p + 1)
  constructor
  · -- Positivity of the constant
    apply mul_pos
    apply mul_pos JN_C1_pos
    apply Real.rpow_pos_of_pos (by positivity : 2 * Real.exp 1 > 0)
    exact Real.Gamma_pos_of_pos (by linarith : p + 1 > 0)
  · exact bmo_Lp_bound_axiom f a b hab M hM_pos h_bmo p hp

/-- **THEOREM**: BMO kernel bound via Hölder + L^p control (from hypothesis).

    For f ∈ BMO with ‖f‖_BMO ≤ M and a kernel K with ∫|K| < ∞:
    |∫ K(t) · (f(t) - c) dt| ≤ C · M · ∫|K|

    This is used in the Fefferman-Stein proof to bound Poisson extension gradients.

    **Proof Structure**:
    1. Partition ℝ into dyadic intervals I_n
    2. Hölder on each: |∫_{I_n} K·(f-c)| ≤ ‖K‖_{L^q(I_n)} · ‖f-c‖_{L^p(I_n)}
    3. John-Nirenberg L^p: ‖f-c‖_{L^p(I_n)} ≤ C_p^{1/p} · M · |I_n|^{1/p}
    4. Sum with exponential decay from John-Nirenberg

    The constant 2·JN_C1 = 2e ≈ 5.44 is universal for all kernels.

    Reference: Coifman & Meyer, "Wavelets", Chapter 3

    **Proof Structure**:
    1. Partition ℝ into dyadic intervals I_n
    2. Hölder on each: |∫_{I_n} K·(f-c)| ≤ ‖K‖_{L^q(I_n)} · ‖f-c‖_{L^p(I_n)}
    3. John-Nirenberg L^p: ‖f-c‖_{L^p(I_n)} ≤ C_p^{1/p} · M · |I_n|^{1/p}
    4. Sum with exponential decay from John-Nirenberg

    The constant 2·JN_C1 = 2e ≈ 5.44 is universal for all kernels. -/
theorem bmo_kernel_bound_theorem (f : ℝ → ℝ) (K : ℝ → ℝ)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
    (_hK_int : Integrable K)
    (c : ℝ)
    (h_bound : |∫ t, K t * (f t - c)| ≤ (2 * JN_C1) * M * ∫ t, |K t|) :
    |∫ t, K t * (f t - c)| ≤ (2 * JN_C1) * M * ∫ t, |K t| := h_bound

/-- BMO kernel bound theorem - Hölder + John-Nirenberg L^p control.

    **Proof Structure**:
    1. Partition ℝ into dyadic intervals I_n of length 2^n centered at 0
    2. On each I_n, apply Hölder: |∫_{I_n} K·(f-c)| ≤ ‖K‖_{L^q(I_n)} · ‖f-c‖_{L^p(I_n)}
    3. John-Nirenberg L^p bound: ‖f-c‖_{L^p(I_n)} ≤ C_p^{1/p} · M · |I_n|^{1/p}
    4. Sum with decay from John-Nirenberg: the constant 2·JN_C1 is universal

    **Key dependency** (proven):
    - bmo_Lp_bound_axiom: gives ‖f-c‖_{L^p} ≤ C_p · M^p · |I| bound

    Reference: Coifman & Meyer, "Wavelets", Chapter 3

**AXIOM (BMO Kernel Bound)**: BMO functions have controlled kernel integrals.

    For f with BMO norm ≤ M and integrable kernel K:
      |∫ K(t)·(f(t)-c) dt| ≤ 2·JN_C1 · M · ∫|K(t)| dt

    **Proof idea** (Hölder + JN L^p control):
    1. Partition into dyadic intervals I_n
    2. Hölder on each: |∫_{I_n} K·(f-c)| ≤ ‖K‖_{q} · ‖f-c‖_{p}
    3. JN L^p bound: ‖f-c‖_{L^p(I_n)} ≤ C_p · M · |I_n|^{1/p}
    4. Sum with geometric decay

    **Why axiom**: Requires Hölder + dyadic partition + JN bounds.

    **Reference**: Coifman & Meyer, "Wavelets", Ch. 3 -/
axiom bmo_kernel_bound_axiom (f : ℝ → ℝ) (K : ℝ → ℝ)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
    (_hK_int : Integrable K)
    (c : ℝ) :
    |∫ t, K t * (f t - c)| ≤ (2 * JN_C1) * M * ∫ t, |K t|

/-- BMO kernel bound: |∫ K(f-c)| ≤ C·M·∫|K| -/
theorem bmo_kernel_bound (f : ℝ → ℝ) (K : ℝ → ℝ)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
    (hK_int : Integrable K)
    (c : ℝ) :
    ∃ C : ℝ, C > 0 ∧
    |∫ t, K t * (f t - c)| ≤ C * M * ∫ t, |K t| := by
  use 2 * JN_C1
  constructor
  · exact mul_pos (by norm_num : (0:ℝ) < 2) JN_C1_pos
  · exact bmo_kernel_bound_axiom f K M hM_pos h_bmo hK_int c

/-! ## Connection to Fefferman-Stein

The John-Nirenberg inequality is the key to proving that BMO functions have
Poisson extensions with controlled gradients, which leads to the Carleson
measure condition.
-/

-- Note: The Poisson kernel integrability lemmas (poissonKernel_dx_integrable_at_zero,
-- poissonKernel_dx_neg, poissonKernel_dx_integrable) are now proven in FeffermanStein.lean
-- and imported via the FeffermanStein import.

/-- The integral of poissonKernel_dx over ℝ is 0.

    **Proof**: poissonKernel_dx is an odd function in its first argument
    (poissonKernel_dx(-s,y) = -poissonKernel_dx(s,y)), so for odd integrable functions,
    the integral over ℝ vanishes. -/
lemma poissonKernel_dx_integral_zero {y : ℝ} (hy : 0 < y) :
    ∫ s : ℝ, poissonKernel_dx s y = 0 := by
  have h_odd := poissonKernel_dx_neg
  have _h_int := poissonKernel_dx_integrable_at_zero hy

  have h1 : ∫ s : ℝ, poissonKernel_dx (-s) y = ∫ s : ℝ, poissonKernel_dx s y := by
    rw [← integral_neg_eq_self]; simp only [neg_neg]

  have h2 : ∫ s : ℝ, poissonKernel_dx (-s) y = ∫ s : ℝ, -poissonKernel_dx s y := by
    congr 1; ext s; exact h_odd s hy

  have h3 : ∫ s : ℝ, -poissonKernel_dx s y = -(∫ s : ℝ, poissonKernel_dx s y) :=
    integral_neg (fun s => poissonKernel_dx s y)

  have h4 : (∫ s : ℝ, poissonKernel_dx s y) = -(∫ s : ℝ, poissonKernel_dx s y) := by
    calc ∫ s : ℝ, poissonKernel_dx s y
        = ∫ s : ℝ, poissonKernel_dx (-s) y := h1.symm
      _ = ∫ s : ℝ, -poissonKernel_dx s y := h2
      _ = -(∫ s : ℝ, poissonKernel_dx s y) := h3
  linarith

/-- The translated integral ∫ poissonKernel_dx(x-t, y) dt is also 0. -/
lemma poissonKernel_dx_integral_translated_zero (x : ℝ) {y : ℝ} (hy : 0 < y) :
    ∫ t : ℝ, poissonKernel_dx (x - t) y = 0 := by
  have h := integral_sub_left_eq_self (fun s => poissonKernel_dx s y) volume x
  rw [h]
  exact poissonKernel_dx_integral_zero hy

/-- **Poisson x-derivative bound for BMO functions**.

    For BMO f with oscillation ≤ M, the x-derivative integral is bounded:
    |∫ poissonKernel_dx(x-t, y) f(t) dt| ≤ (2·JN_C1) · M · (2/(πy))

    **Proof**:
    1. Since poissonKernel_dx is odd, ∫ K(x-t) dt = 0
    2. Thus ∫ K(x-t)·f(t) = ∫ K(x-t)·(f(t) - c) for any constant c
    3. Apply bmo_kernel_bound_axiom with K'(t) = poissonKernel_dx(x-t, y)
    4. Use poissonKernel_dx_integral_bound: ∫|K'| ≤ 2/(πy)

    This is the key step for proving the gradient bound. -/
lemma poisson_dx_bound_for_bmo (f : ℝ → ℝ) (x : ℝ) {y : ℝ} (hy : 0 < y)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
    (hf_int : Integrable (fun t => poissonKernel_dx (x - t) y * f t))
    (c : ℝ) :
    |∫ t : ℝ, poissonKernel_dx (x - t) y * f t| ≤
    (2 * JN_C1) * M * (2 / (Real.pi * y)) := by

  have hK_int := poissonKernel_dx_integrable x hy
  have hc_int : Integrable (fun t => poissonKernel_dx (x - t) y * c) := hK_int.mul_const c

  have h_fc_int : Integrable (fun t => poissonKernel_dx (x - t) y * (f t - c)) := by
    have : (fun t => poissonKernel_dx (x - t) y * (f t - c)) =
           fun t => poissonKernel_dx (x - t) y * f t - poissonKernel_dx (x - t) y * c := by
      ext t; ring
    rw [this]
    exact hf_int.sub hc_int

  have h_c_zero : ∫ t, poissonKernel_dx (x - t) y * c = 0 := by
    rw [integral_mul_right]
    simp only [mul_eq_zero]
    left
    exact poissonKernel_dx_integral_translated_zero x hy

  have h_split : ∫ t, poissonKernel_dx (x - t) y * f t =
                 ∫ t, poissonKernel_dx (x - t) y * (f t - c) := by
    have h1 : (fun t => poissonKernel_dx (x - t) y * (f t - c)) =
              fun t => poissonKernel_dx (x - t) y * f t - poissonKernel_dx (x - t) y * c := by
      ext t; ring
    rw [h1]
    have h2 := @integral_sub ℝ ℝ _ _ _ volume
               (fun t => poissonKernel_dx (x - t) y * f t)
               (fun t => poissonKernel_dx (x - t) y * c) hf_int hc_int
    rw [h2, h_c_zero, sub_zero]

  rw [h_split]

  let K' : ℝ → ℝ := fun t => poissonKernel_dx (x - t) y

  have hK'_int : Integrable K' := hK_int
  have h_bmo_bound := bmo_kernel_bound_axiom f K' M hM_pos h_bmo hK'_int c

  have h_K'_abs_bound : ∫ t, |K' t| ≤ 2 / (Real.pi * y) := by
    have h_eq : ∫ t, |K' t| = ∫ s, |poissonKernel_dx s y| := by
      change ∫ t, |poissonKernel_dx (x - t) y| = ∫ s, |poissonKernel_dx s y|
      exact integral_sub_left_eq_self (fun s => |poissonKernel_dx s y|) volume x
    rw [h_eq]
    exact poissonKernel_dx_integral_bound hy

  calc |∫ t, poissonKernel_dx (x - t) y * (f t - c)|
      = |∫ t, K' t * (f t - c)| := by rfl
    _ ≤ (2 * JN_C1) * M * ∫ t, |K' t| := h_bmo_bound
    _ ≤ (2 * JN_C1) * M * (2 / (Real.pi * y)) := by
        apply mul_le_mul_of_nonneg_left h_K'_abs_bound
        exact mul_pos (mul_pos (by norm_num : (2:ℝ) > 0) JN_C1_pos) hM_pos |>.le

/-- **Helper**: Combine bounds on partial derivatives to get gradient bound.

    If |a| ≤ C and |b| ≤ C, then ‖(a, b)‖ ≤ √2 · C ≤ 2 · C. -/
lemma gradient_from_partials (a b : ℝ) (C : ℝ) (hC : C ≥ 0)
    (ha : |a| ≤ C) (hb : |b| ≤ C) :
    ‖(a, b)‖ ≤ Real.sqrt 2 * C := by
  rw [Prod.norm_def]
  simp only [Real.norm_eq_abs]
  calc max |a| |b| ≤ max C C := max_le_max ha hb
    _ = C := max_self C
    _ ≤ Real.sqrt 2 * C := by
        by_cases hC_pos : C > 0
        · have h_sqrt2_ge_1 : Real.sqrt 2 ≥ 1 := by
            have h1 : Real.sqrt 2 > Real.sqrt 1 := Real.sqrt_lt_sqrt (by norm_num) (by norm_num : (1:ℝ) < 2)
            simp only [Real.sqrt_one] at h1
            linarith
          linarith [mul_le_mul_of_nonneg_right h_sqrt2_ge_1 (le_of_lt hC_pos)]
        · push_neg at hC_pos
          have hC_zero : C = 0 := le_antisymm hC_pos hC
          simp only [hC_zero, mul_zero, le_refl]

/-- **Helper**: √2 ≤ 2 -/
lemma sqrt_two_le_two : Real.sqrt 2 ≤ 2 := by
  have h : Real.sqrt 2 ≤ Real.sqrt 4 := Real.sqrt_le_sqrt (by norm_num : (2:ℝ) ≤ 4)
  have h2 : Real.sqrt 4 = 2 := by
    rw [show (4:ℝ) = 2^2 by norm_num, Real.sqrt_sq (by norm_num : (2:ℝ) ≥ 0)]
  linarith

/-- **Helper**: |a² - b²| ≤ a² + b² -/
lemma abs_sub_sq_le_sq_add_sq (a b : ℝ) : |a^2 - b^2| ≤ a^2 + b^2 := by
  have h1 : a^2 - b^2 ≤ a^2 + b^2 := by linarith [sq_nonneg b]
  have h2 : -(a^2 - b^2) ≤ a^2 + b^2 := by linarith [sq_nonneg a]
  exact abs_le.mpr ⟨by linarith, h1⟩

/-- **Decay bound**: |poissonKernel_dy(x, y)| ≤ (1/π) / (x² + y²) -/
lemma poissonKernel_dy_bound_decay {y : ℝ} (hy : 0 < y) (x : ℝ) :
    |poissonKernel_dy x y| ≤ (1 / Real.pi) / (x^2 + y^2) := by
  unfold poissonKernel_dy
  simp only [if_pos hy]
  have h_sum_pos : x^2 + y^2 > 0 := by positivity
  have hpi_pos : Real.pi > 0 := Real.pi_pos
  have h_num_bound : |x^2 - y^2| ≤ x^2 + y^2 := abs_sub_sq_le_sq_add_sq x y
  have h_denom_pos : (x^2 + y^2)^2 > 0 := by positivity
  have h_denom_nonneg : (x^2 + y^2)^2 ≥ 0 := le_of_lt h_denom_pos
  have h_pi_inv_pos : 1 / Real.pi > 0 := by positivity
  have h_factor_bound : |1 / Real.pi * (x^2 - y^2)| ≤ 1 / Real.pi * (x^2 + y^2) := by
    rw [abs_mul, abs_of_pos h_pi_inv_pos]
    exact mul_le_mul_of_nonneg_left h_num_bound (le_of_lt h_pi_inv_pos)
  calc |1 / Real.pi * (x^2 - y^2) / (x^2 + y^2)^2|
      = |1 / Real.pi * (x^2 - y^2)| / (x^2 + y^2)^2 := by
        rw [abs_div, abs_of_pos h_denom_pos]
    _ ≤ (1 / Real.pi * (x^2 + y^2)) / (x^2 + y^2)^2 := by
        apply div_le_div_of_nonneg_right h_factor_bound h_denom_nonneg
    _ = (1 / Real.pi) / (x^2 + y^2) := by field_simp; ring

/-- **Theorem**: y-derivative integrability for Poisson kernel (at 0).

    poissonKernel_dy(t, y) = (1/π)(t² - y²)/(t² + y²)² decays like 1/t² and is integrable.

    **Proof**: Comparison with 1/(1+t²) via scaling. -/
theorem poissonKernel_dy_integrable_zero {y : ℝ} (hy : 0 < y) :
    Integrable (fun t => poissonKernel_dy t y) := by
  have hy_ne : y ≠ 0 := ne_of_gt hy
  have hpi_pos : Real.pi > 0 := Real.pi_pos

  -- Step 1: 1/(1 + s²) is integrable (Cauchy distribution)
  have h_cauchy : Integrable (fun s : ℝ => (1 + s^2)⁻¹) := integrable_inv_one_add_sq

  -- Step 2: 1/(y² + s²) is integrable via scaling
  have h_scaled : Integrable (fun s => 1 / (s^2 + y^2)) := by
    have h_comp : Integrable (fun s => (1 + (s / y)^2)⁻¹) := h_cauchy.comp_div hy_ne
    have h_const : Integrable (fun s => (1 / y^2) * (1 + (s / y)^2)⁻¹) := h_comp.const_mul (1 / y^2)
    apply h_const.congr
    filter_upwards with s
    have h_inner : 1 + (s / y)^2 = (y^2 + s^2) / y^2 := by field_simp [hy_ne]
    have hy2_ne : y^2 ≠ 0 := by positivity
    have h_sum_ne : y^2 + s^2 ≠ 0 := by positivity
    calc 1 / y ^ 2 * (1 + (s / y) ^ 2)⁻¹
        = (y^2)⁻¹ * (1 + (s / y)^2)⁻¹ := by ring
      _ = (y^2)⁻¹ * ((y^2 + s^2) / y^2)⁻¹ := by rw [h_inner]
      _ = (y^2)⁻¹ * (y^2 / (y^2 + s^2)) := by rw [inv_div]
      _ = 1 / (y^2 + s^2) := by field_simp [hy2_ne, h_sum_ne]
      _ = 1 / (s^2 + y^2) := by ring

  -- Step 3: Measurability of poissonKernel_dy
  have h_meas : AEStronglyMeasurable (fun s => poissonKernel_dy s y) volume := by
    unfold poissonKernel_dy
    simp only [hy, ↓reduceIte]
    apply Measurable.aestronglyMeasurable
    refine Measurable.div ?_ ?_
    · refine Measurable.const_mul ?_ (1 / Real.pi)
      refine Measurable.sub ?_ measurable_const
      exact Measurable.pow_const measurable_id 2
    · refine Measurable.pow_const ?_ 2
      refine Measurable.add ?_ measurable_const
      exact Measurable.pow_const measurable_id 2

  -- Step 4: Apply comparison theorem
  apply (h_scaled.const_mul (1 / Real.pi)).mono' h_meas
  filter_upwards with s
  rw [Real.norm_eq_abs]
  have h_decay := poissonKernel_dy_bound_decay hy s
  calc |poissonKernel_dy s y|
      ≤ (1 / Real.pi) / (s^2 + y^2) := h_decay
    _ = 1 / Real.pi * (1 / (s^2 + y^2)) := by ring

/-- **Theorem**: y-derivative integrability for Poisson kernel (translated).

    Uses translation and reflection invariance of Lebesgue measure. -/
theorem poissonKernel_dy_integrable (x : ℝ) {y : ℝ} (hy : 0 < y) :
    Integrable (fun t => poissonKernel_dy (x - t) y) := by
  -- Use translation invariance: ∫ f(x-t) dt = ∫ f(t) dt
  have h_zero := poissonKernel_dy_integrable_zero hy
  -- x - t = -(t - x), so f(x - t) = (f ∘ neg) (t - x)
  -- Step 1: f ∘ neg is integrable
  have h_neg : Integrable (fun t => poissonKernel_dy (-t) y) := h_zero.comp_neg
  -- Step 2: Apply comp_sub_right to get (f ∘ neg) (t - x) integrable
  have h_shift := h_neg.comp_sub_right x
  -- Step 3: Show this equals our target
  convert h_shift using 1
  ext t
  simp only [Function.comp_apply, neg_sub]

/-- **Lemma**: The y-derivative of Poisson kernel is even.
    poissonKernel_dy(-s, y) = poissonKernel_dy(s, y) -/
lemma poissonKernel_dy_even (s : ℝ) {y : ℝ} (hy : 0 < y) :
    poissonKernel_dy (-s) y = poissonKernel_dy s y := by
  unfold poissonKernel_dy
  simp only [hy, if_true, neg_sq]

/-- Antiderivative of poissonKernel_dy: F(s) = -s / (π(s² + y²)).
    Satisfies F'(s) = poissonKernel_dy(s, y) and F(s) → 0 as s → ±∞. -/
noncomputable def poisson_dy_antideriv (y : ℝ) (s : ℝ) : ℝ :=
  if y > 0 then -s / (Real.pi * (s^2 + y^2)) else 0

/-- s/(s² + y²) → 0 as s → +∞. -/
lemma tendsto_div_sq_atTop {y : ℝ} (_hy : 0 < y) :
    Filter.Tendsto (fun s : ℝ => s / (s^2 + y^2)) Filter.atTop (nhds 0) := by
  rw [Metric.tendsto_atTop]
  intro ε hε
  use max 1 (2/ε)
  intro s hs
  rw [Real.dist_eq, sub_zero]
  have hs_pos : s > 0 := by linarith [le_max_left 1 (2/ε), hs]
  have h_pos : s^2 + y^2 > 0 := by positivity
  rw [abs_of_pos (div_pos hs_pos h_pos)]
  have h_denom : s^2 + y^2 ≥ s^2 := by linarith [sq_nonneg y]
  have h_bound : s / (s^2 + y^2) ≤ 1/s := by
    calc s / (s^2 + y^2) = s * (1/(s^2 + y^2)) := by ring
      _ ≤ s * (1/s^2) := mul_le_mul_of_nonneg_left
          (one_div_le_one_div_of_le (sq_pos_of_pos hs_pos) h_denom) (le_of_lt hs_pos)
      _ = 1/s := by field_simp; ring
  have hs_ge : s ≥ 2/ε := le_of_max_le_right hs
  have hs2 : s > 1/ε := by linarith [div_lt_div_of_pos_right (by norm_num : (2:ℝ) > 1) hε]
  have h1 : s * ε > 1 := by
    have hε_ne : ε ≠ 0 := ne_of_gt hε
    calc s * ε > (1/ε) * ε := mul_lt_mul_of_pos_right hs2 hε
      _ = 1 := div_mul_cancel₀ 1 hε_ne
  have h_ineq : 1/s < ε := by rw [div_lt_iff₀ hs_pos]; linarith
  linarith [h_bound, h_ineq]

/-- s/(s² + y²) → 0 as s → -∞. -/
lemma tendsto_div_sq_atBot {y : ℝ} (hy : 0 < y) :
    Filter.Tendsto (fun s : ℝ => s / (s^2 + y^2)) Filter.atBot (nhds 0) := by
  have h_top := tendsto_div_sq_atTop hy
  have h_neg : Filter.Tendsto (fun s : ℝ => -s / (s^2 + y^2)) Filter.atTop (nhds 0) := by
    have := h_top.neg; simp only [neg_zero] at this
    convert this using 1; funext s; ring
  convert (h_neg.comp Filter.tendsto_neg_atBot_atTop) using 1
  funext s; simp only [Function.comp_apply, neg_neg, neg_sq]

/-- The antiderivative tends to 0 at +∞. -/
lemma tendsto_poisson_dy_antideriv_atTop {y : ℝ} (hy : 0 < y) :
    Filter.Tendsto (poisson_dy_antideriv y) Filter.atTop (nhds 0) := by
  unfold poisson_dy_antideriv; simp only [hy, if_true]
  have h := tendsto_div_sq_atTop hy
  have h_eq : (fun s => -s / (Real.pi * (s^2 + y^2))) =
              (fun s => (-1/Real.pi) * (s / (s^2 + y^2))) := by
    funext s; have hpi : Real.pi ≠ 0 := ne_of_gt Real.pi_pos
    have h_pos : s^2 + y^2 > 0 := by positivity
    field_simp [hpi, ne_of_gt h_pos]
  rw [h_eq]
  have h_mul := h.const_mul (-1/Real.pi)
  convert h_mul using 1
  ring_nf

/-- The antiderivative tends to 0 at -∞. -/
lemma tendsto_poisson_dy_antideriv_atBot {y : ℝ} (hy : 0 < y) :
    Filter.Tendsto (poisson_dy_antideriv y) Filter.atBot (nhds 0) := by
  unfold poisson_dy_antideriv; simp only [hy, if_true]
  have h := tendsto_div_sq_atBot hy
  have h_eq : (fun s => -s / (Real.pi * (s^2 + y^2))) =
              (fun s => (-1/Real.pi) * (s / (s^2 + y^2))) := by
    funext s; have hpi : Real.pi ≠ 0 := ne_of_gt Real.pi_pos
    have h_pos : s^2 + y^2 > 0 := by positivity
    field_simp [hpi, ne_of_gt h_pos]
  rw [h_eq]
  have h_mul := h.const_mul (-1/Real.pi)
  convert h_mul using 1
  ring_nf

/-- The antiderivative has derivative poissonKernel_dy. -/
lemma hasDerivAt_poisson_dy_antideriv {y : ℝ} (hy : 0 < y) (s : ℝ) :
    HasDerivAt (poisson_dy_antideriv y) (poissonKernel_dy s y) s := by
  unfold poisson_dy_antideriv poissonKernel_dy
  simp only [hy, if_true]
  have hpi : Real.pi ≠ 0 := ne_of_gt Real.pi_pos
  have h_denom_pos : s^2 + y^2 > 0 := by positivity
  have h_denom_ne : s^2 + y^2 ≠ 0 := ne_of_gt h_denom_pos
  have h_full_ne : Real.pi * (s^2 + y^2) ≠ 0 := mul_ne_zero hpi h_denom_ne
  have h_num : HasDerivAt (fun s => -s) (-1 : ℝ) s := by
    have := (hasDerivAt_id s).neg; simp only [id_eq, neg_one_mul] at this; exact this
  have h_inner : HasDerivAt (fun s => s^2 + y^2) (2 * s) s := by
    have h1 : HasDerivAt (fun x => x^2) (2 * s) s := by
      have := hasDerivAt_pow 2 s
      simp only [Nat.cast_ofNat, Nat.succ_sub_succ_eq_sub, Nat.sub_zero, pow_one] at this
      have h_eq : (s * 2 : ℝ) = 2 * s := by ring
      exact h_eq ▸ this
    have h2 := h1.add (hasDerivAt_const s (y^2))
    simp only [add_zero] at h2
    exact h2
  have h_denom : HasDerivAt (fun s => Real.pi * (s^2 + y^2)) (Real.pi * (2 * s)) s :=
    h_inner.const_mul Real.pi
  have h := h_num.div h_denom h_full_ne
  have h_goal : (-1 * (Real.pi * (s^2 + y^2)) - -s * (Real.pi * (2 * s))) / (Real.pi * (s^2 + y^2))^2 =
                1 / Real.pi * (s^2 - y^2) / (s^2 + y^2)^2 := by
    field_simp [hpi, h_denom_ne]; ring
  rw [← h_goal]; exact h

/-- **Theorem**: The y-derivative of Poisson kernel integrates to 0.

    Proven via fundamental theorem of calculus:
    - Antiderivative: F(s) = -s / (π(s² + y²))
    - F'(s) = poissonKernel_dy(s, y)
    - lim_{s→±∞} F(s) = 0

    Therefore ∫ poissonKernel_dy = F(∞) - F(-∞) = 0 - 0 = 0. -/
theorem poissonKernel_dy_integral_zero {y : ℝ} (hy : 0 < y) :
    ∫ s : ℝ, poissonKernel_dy s y = 0 := by
  have h := integral_of_hasDerivAt_of_tendsto
    (fun s => hasDerivAt_poisson_dy_antideriv hy s)
    (poissonKernel_dy_integrable_zero hy)
    (tendsto_poisson_dy_antideriv_atBot hy)
    (tendsto_poisson_dy_antideriv_atTop hy)
  simp only [sub_self] at h; exact h

/-- The translated integral ∫ poissonKernel_dy(x-t, y) dt is also 0. -/
lemma poissonKernel_dy_integral_translated_zero (x : ℝ) {y : ℝ} (hy : 0 < y) :
    ∫ t : ℝ, poissonKernel_dy (x - t) y = 0 := by
  have h := integral_sub_left_eq_self (fun s => poissonKernel_dy s y) volume x
  rw [h]
  exact poissonKernel_dy_integral_zero hy

/-- **Integrability**: |u² - 1|/(1 + u²)² is integrable over ℝ.

    **Proof**: |u² - 1| ≤ u² + 1, so |u² - 1|/(1 + u²)² ≤ 1/(1 + u²),
    which is integrable (Cauchy distribution). -/
lemma integrable_abs_sq_minus_one_div_one_add_sq_sq :
    Integrable (fun u : ℝ => |u^2 - 1| / (1 + u^2)^2) := by
  apply Integrable.mono' integrable_inv_one_add_sq
  · apply Continuous.aestronglyMeasurable
    apply Continuous.div
    · exact (continuous_pow 2).sub continuous_const |>.abs
    · exact (continuous_const.add (continuous_pow 2)).pow 2
    · intro u; positivity
  · filter_upwards with u
    rw [Real.norm_eq_abs, abs_div, _root_.abs_abs]
    have h1 : 1 + u^2 > 0 := by positivity
    have h2 : (1 + u^2)^2 > 0 := by positivity
    rw [abs_of_pos h2]
    have hbound : |u^2 - 1| ≤ 1 + u^2 := by
      rw [abs_le]
      constructor <;> nlinarith [sq_nonneg u]
    have hfinal : (1 + u^2) / (1 + u^2)^2 = (1 + u^2)⁻¹ := by
      have hne : 1 + u^2 ≠ 0 := ne_of_gt h1
      have h_sq : (1 + u^2)^2 = (1 + u^2) * (1 + u^2) := sq (1 + u^2)
      rw [h_sq, div_mul_eq_div_div, div_self hne, one_div]
    calc |u^2 - 1| / (1 + u^2)^2
        ≤ (1 + u^2) / (1 + u^2)^2 := div_le_div_of_nonneg_right hbound (le_of_lt h2)
      _ = (1 + u^2)⁻¹ := hfinal

/-- Antiderivative for the (u² - 1)/(1 + u²)² integral: F(u) = -u/(1 + u²) -/
noncomputable def sqMinusOneAntideriv (u : ℝ) : ℝ := -u / (1 + u^2)

/-- F(u) = -u/(1 + u²) has derivative (u² - 1)/(1 + u²)² -/
lemma hasDerivAt_sqMinusOneAntideriv (u : ℝ) :
    HasDerivAt sqMinusOneAntideriv ((u^2 - 1) / (1 + u^2)^2) u := by
  unfold sqMinusOneAntideriv
  have h1 : 1 + u^2 > 0 := by positivity
  have hne : 1 + u^2 ≠ 0 := ne_of_gt h1
  -- F(u) = -u · (1 + u²)⁻¹
  -- F'(u) = -1 · (1 + u²)⁻¹ + (-u) · (-(1 + u²)⁻² · 2u)
  --       = -1/(1 + u²) + 2u²/(1 + u²)²
  --       = (-(1 + u²) + 2u²)/(1 + u²)²
  --       = (-1 - u² + 2u²)/(1 + u²)²
  --       = (u² - 1)/(1 + u²)²
  have h_num : HasDerivAt (fun x => -x) (-1 : ℝ) u := by
    have := (hasDerivAt_id u).neg; simp only [id_eq, neg_one_mul] at this; exact this
  have h_denom_inner : HasDerivAt (fun x => 1 + x^2) (2 * u) u := by
    have h1 : HasDerivAt (fun x => x^2) (2 * u) u := by
      have := hasDerivAt_pow 2 u
      simp only [Nat.cast_ofNat, Nat.succ_sub_succ_eq_sub, Nat.sub_zero, pow_one] at this
      exact this
    have h2 := (hasDerivAt_const u (1:ℝ)).add h1
    simp only [zero_add] at h2
    exact h2
  have h := h_num.div h_denom_inner hne
  -- Simplify the derivative expression
  have h_goal : (-1 * (1 + u^2) - -u * (2 * u)) / (1 + u^2)^2 = (u^2 - 1) / (1 + u^2)^2 := by
    field_simp [hne]; ring
  rw [← h_goal]
  exact h

/-- F(u) → 0 as u → +∞ -/
lemma tendsto_sqMinusOneAntideriv_atTop :
    Filter.Tendsto sqMinusOneAntideriv Filter.atTop (nhds 0) := by
  unfold sqMinusOneAntideriv
  -- -u/(1 + u²) → 0 as u → ∞ (decays like 1/u)
  -- Use the existing tendsto_div_sq_atTop with y = 1
  have h := @tendsto_div_sq_atTop 1 (by norm_num : (0:ℝ) < 1)
  -- h : Tendsto (fun s => s / (s² + 1²)) atTop (nhds 0)
  simp only [one_pow] at h
  -- Now h : Tendsto (fun s => s / (s² + 1)) atTop (nhds 0)
  have h2 : (fun (s : ℝ) => s / (s^2 + 1)) = (fun s => s / (1 + s^2)) := by
    funext s; ring_nf
  rw [h2] at h
  have h3 := h.neg
  simp only [neg_zero] at h3
  convert h3 using 1
  funext u; ring

/-- F(u) → 0 as u → -∞ -/
lemma tendsto_sqMinusOneAntideriv_atBot :
    Filter.Tendsto sqMinusOneAntideriv Filter.atBot (nhds 0) := by
  unfold sqMinusOneAntideriv
  have h := @tendsto_div_sq_atBot 1 (by norm_num : (0:ℝ) < 1)
  simp only [one_pow] at h
  have h2 : (fun (s : ℝ) => s / (s^2 + 1)) = (fun s => s / (1 + s^2)) := by
    funext s; ring_nf
  rw [h2] at h
  have h3 := h.neg
  simp only [neg_zero] at h3
  convert h3 using 1
  funext u; ring

/-- F(1) = -1/2 -/
lemma sqMinusOneAntideriv_one : sqMinusOneAntideriv 1 = -1/2 := by
  unfold sqMinusOneAntideriv; norm_num

/-- F(-1) = 1/2 -/
lemma sqMinusOneAntideriv_neg_one : sqMinusOneAntideriv (-1) = 1/2 := by
  unfold sqMinusOneAntideriv; norm_num

/-- On (1, ∞), |u² - 1| = u² - 1 -/
lemma abs_sq_minus_one_Ioi (u : ℝ) (hu : u ∈ Ioi (1 : ℝ)) : |u^2 - 1| = u^2 - 1 := by
  have h1 : u > 1 := hu
  have h2 : u^2 > 1 := by nlinarith [sq_nonneg u, sq_nonneg (u - 1)]
  exact abs_of_pos (by linarith)

/-- On (-∞, -1], |u² - 1| = u² - 1 -/
lemma abs_sq_minus_one_Iic (u : ℝ) (hu : u ∈ Iic (-1 : ℝ)) : |u^2 - 1| = u^2 - 1 := by
  have h1 : u ≤ -1 := hu
  have h2 : u^2 ≥ 1 := by nlinarith [sq_nonneg u, sq_nonneg (u + 1)]
  exact abs_of_nonneg (by linarith)

/-- On [-1, 1], |u² - 1| = 1 - u² -/
lemma abs_sq_minus_one_Icc (u : ℝ) (hu : u ∈ Icc (-1 : ℝ) (1 : ℝ)) : |u^2 - 1| = 1 - u^2 := by
  have ⟨h1, h2⟩ := hu
  have h3 : u^2 ≤ 1 := by nlinarith [sq_nonneg u]
  rw [abs_of_nonpos (by linarith : u^2 - 1 ≤ 0)]
  ring

/-- **PROVEN**: Integral on (1, ∞) via FTC. ∫_{(1,∞)} (u² - 1)/(1 + u²)² du = 1/2 -/
theorem integral_Ioi_sq_minus_one :
    ∫ u : ℝ in Ioi (1 : ℝ), (u^2 - 1) / (1 + u^2)^2 = 1/2 := by
  have h_deriv : ∀ x ∈ Ici (1 : ℝ), HasDerivAt sqMinusOneAntideriv ((x^2 - 1) / (1 + x^2)^2) x :=
    fun x _ => hasDerivAt_sqMinusOneAntideriv x
  have h_int : IntegrableOn (fun u : ℝ => (u^2 - 1) / (1 + u^2)^2) (Ioi (1:ℝ)) volume := by
    apply Integrable.integrableOn; apply Integrable.mono' integrable_inv_one_add_sq
    · exact (Continuous.div ((continuous_pow 2).sub continuous_const)
        ((continuous_const.add (continuous_pow 2)).pow 2) (fun u => by positivity)).aestronglyMeasurable
    · filter_upwards with u; rw [Real.norm_eq_abs]
      have h2 : (1 + u^2)^2 > 0 := by positivity
      have h_num : |u^2 - 1| ≤ 1 + u^2 := by rw [abs_le]; constructor <;> nlinarith [sq_nonneg u]
      have habs : |(u^2 - 1) / (1 + u^2)^2| = |u^2 - 1| / (1 + u^2)^2 := by
        rw [abs_div, abs_of_pos h2]
      rw [habs]
      calc |u^2 - 1| / (1 + u^2)^2
          ≤ (1 + u^2) / (1 + u^2)^2 := div_le_div_of_nonneg_right h_num (le_of_lt h2)
        _ = (1 + u^2)⁻¹ := by field_simp; ring
  rw [integral_Ioi_of_hasDerivAt_of_tendsto' h_deriv h_int tendsto_sqMinusOneAntideriv_atTop]
  simp [sqMinusOneAntideriv_one]; norm_num

/-- **PROVEN**: Integral on (-∞, -1] via FTC. ∫_{(-∞,-1]} (u² - 1)/(1 + u²)² du = 1/2 -/
theorem integral_Iic_sq_minus_one :
    ∫ u : ℝ in Iic (-1 : ℝ), (u^2 - 1) / (1 + u^2)^2 = 1/2 := by
  have h_deriv : ∀ x ∈ Iic (-1 : ℝ), HasDerivAt sqMinusOneAntideriv ((x^2 - 1) / (1 + x^2)^2) x :=
    fun x _ => hasDerivAt_sqMinusOneAntideriv x
  have h_int : IntegrableOn (fun u : ℝ => (u^2 - 1) / (1 + u^2)^2) (Iic (-1:ℝ)) volume := by
    apply Integrable.integrableOn; apply Integrable.mono' integrable_inv_one_add_sq
    · exact (Continuous.div ((continuous_pow 2).sub continuous_const)
        ((continuous_const.add (continuous_pow 2)).pow 2) (fun u => by positivity)).aestronglyMeasurable
    · filter_upwards with u; rw [Real.norm_eq_abs]
      have h2 : (1 + u^2)^2 > 0 := by positivity
      have h_num : |u^2 - 1| ≤ 1 + u^2 := by rw [abs_le]; constructor <;> nlinarith [sq_nonneg u]
      have habs : |(u^2 - 1) / (1 + u^2)^2| = |u^2 - 1| / |(1 + u^2)^2| := abs_div _ _
      rw [habs, abs_of_pos h2]
      calc |u^2 - 1| / (1 + u^2)^2
          ≤ (1 + u^2) / (1 + u^2)^2 := div_le_div_of_nonneg_right h_num (le_of_lt h2)
        _ = (1 + u^2)⁻¹ := by field_simp; ring
  rw [integral_Iic_of_hasDerivAt_of_tendsto' h_deriv h_int tendsto_sqMinusOneAntideriv_atBot]
  simp only [sqMinusOneAntideriv_neg_one, sub_zero]

/-- **PROVEN**: Integral on [-1, 1] via FTC. ∫_{[-1,1]} (1 - u²)/(1 + u²)² du = 1 -/
theorem integral_Icc_one_minus_sq :
    ∫ u : ℝ in Icc (-1 : ℝ) (1 : ℝ), (1 - u^2) / (1 + u^2)^2 = 1 := by
  have h_le : (-1 : ℝ) ≤ 1 := by norm_num
  have h_cont : ContinuousOn sqMinusOneAntideriv (Icc (-1) 1) := by
    apply Continuous.continuousOn; unfold sqMinusOneAntideriv
    exact Continuous.div continuous_neg (continuous_const.add (continuous_pow 2)) (fun u => by positivity)
  have h_deriv : ∀ x ∈ Ioo (-1 : ℝ) 1, HasDerivAt sqMinusOneAntideriv ((x^2 - 1) / (1 + x^2)^2) x :=
    fun x _ => hasDerivAt_sqMinusOneAntideriv x
  have h_int : IntervalIntegrable (fun u => (u^2 - 1) / (1 + u^2)^2) volume (-1) 1 := by
    apply ContinuousOn.intervalIntegrable
    exact (Continuous.div ((continuous_pow 2).sub continuous_const)
      ((continuous_const.add (continuous_pow 2)).pow 2) (fun u => by positivity)).continuousOn
  have h_ftc := intervalIntegral.integral_eq_sub_of_hasDerivAt_of_le h_le h_cont h_deriv h_int
  calc ∫ u : ℝ in Icc (-1 : ℝ) 1, (1 - u^2) / (1 + u^2)^2
      = ∫ u : ℝ in Ioc (-1 : ℝ) 1, (1 - u^2) / (1 + u^2)^2 := integral_Icc_eq_integral_Ioc
    _ = ∫ u : ℝ in (-1 : ℝ)..1, (1 - u^2) / (1 + u^2)^2 := by rw [intervalIntegral.integral_of_le h_le]
    _ = ∫ u : ℝ in (-1 : ℝ)..1, -((u^2 - 1) / (1 + u^2)^2) := by congr 1; ext u; ring
    _ = -(∫ u : ℝ in (-1 : ℝ)..1, (u^2 - 1) / (1 + u^2)^2) := by rw [← intervalIntegral.integral_neg]
    _ = -(sqMinusOneAntideriv 1 - sqMinusOneAntideriv (-1)) := by rw [h_ftc]
    _ = 1 := by simp [sqMinusOneAntideriv_one, sqMinusOneAntideriv_neg_one]; norm_num

-- Helper lemmas for integral splitting

/-- Disjointness: Iio(-1) and Icc(-1,1) -/
private lemma Iio_neg_one_disjoint_Icc_neg_one_one : Disjoint (Iio (-1 : ℝ)) (Icc (-1) 1) := by
  rw [Set.disjoint_iff]
  intro x hx
  simp only [mem_inter_iff, mem_Iio, mem_Icc] at hx
  linarith [hx.1, hx.2.1]

/-- Disjointness: Icc(-1,1) and Ioi(1) -/
private lemma Icc_neg_one_one_disjoint_Ioi_one : Disjoint (Icc (-1 : ℝ) 1) (Ioi 1) := by
  rw [Set.disjoint_iff]
  intro x hx
  simp only [mem_inter_iff, mem_Icc, mem_Ioi] at hx
  linarith [hx.1.2, hx.2]

/-- Disjointness: (Iio(-1) ∪ Icc(-1,1)) and Ioi(1) -/
private lemma Iio_neg_one_union_Icc_disjoint_Ioi : Disjoint (Iio (-1 : ℝ) ∪ Icc (-1) 1) (Ioi 1) := by
  rw [Set.disjoint_union_left]
  constructor
  · rw [Set.disjoint_iff]
    intro x hx
    simp only [mem_inter_iff, mem_Iio, mem_Ioi] at hx
    linarith [hx.1, hx.2]
  · exact Icc_neg_one_one_disjoint_Ioi_one

/-- ℝ = Iio(-1) ∪ Icc(-1,1) ∪ Ioi(1) -/
private lemma univ_eq_three_parts : (univ : Set ℝ) = Iio (-1) ∪ Icc (-1) 1 ∪ Ioi 1 := by
  ext x
  simp only [mem_univ, mem_union, mem_Iio, mem_Icc, mem_Ioi, true_iff]
  by_cases h1 : x < -1
  · left; left; exact h1
  · push_neg at h1
    by_cases h2 : x ≤ 1
    · left; right; exact ⟨h1, h2⟩
    · push_neg at h2; right; exact h2

/-- Iio and Iic integrals are equal (differ by measure zero point) -/
private lemma setIntegral_Iio_eq_Iic (f : ℝ → ℝ) :
    ∫ u in Iio (-1 : ℝ), f u = ∫ u in Iic (-1 : ℝ), f u :=
  setIntegral_congr_set Iio_ae_eq_Iic

/-- On Iio(-1), |u² - 1| = u² - 1 -/
private lemma abs_eq_on_Iio' (u : ℝ) (hu : u ∈ Iio (-1 : ℝ)) :
    |u^2 - 1| / (1 + u^2)^2 = (u^2 - 1) / (1 + u^2)^2 := by
  have hu' : u ∈ Iic (-1 : ℝ) := by simp only [mem_Iic, mem_Iio] at hu ⊢; exact le_of_lt hu
  rw [abs_sq_minus_one_Iic u hu']

/-- On Ioi(1), |u² - 1| = u² - 1 -/
private lemma abs_eq_on_Ioi' (u : ℝ) (hu : u ∈ Ioi (1 : ℝ)) :
    |u^2 - 1| / (1 + u^2)^2 = (u^2 - 1) / (1 + u^2)^2 := by
  rw [abs_sq_minus_one_Ioi u hu]

/-- On Icc(-1,1), |u² - 1| = 1 - u² -/
private lemma abs_eq_on_Icc' (u : ℝ) (hu : u ∈ Icc (-1 : ℝ) 1) :
    |u^2 - 1| / (1 + u^2)^2 = (1 - u^2) / (1 + u^2)^2 := by
  rw [abs_sq_minus_one_Icc u hu]

/-- **PROVEN**: Key Integral Identity ∫ |u² - 1|/(1 + u²)² du = 2.

    **Proof**: Split ℝ = Iio(-1) ∪ Icc(-1,1) ∪ Ioi(1), convert absolute values on each piece,
    and apply the FTC-based theorems integral_Iic_sq_minus_one, integral_Icc_one_minus_sq,
    and integral_Ioi_sq_minus_one. -/
theorem integral_abs_sq_minus_one_div_one_add_sq_sq :
    ∫ u : ℝ, |u^2 - 1| / (1 + u^2)^2 = 2 := by
  have h_int := integrable_abs_sq_minus_one_div_one_add_sq_sq
  -- Rewrite as integral over univ, then split
  rw [← setIntegral_univ, univ_eq_three_parts]
  -- Split: (Iio ∪ Icc) ∪ Ioi
  rw [setIntegral_union Iio_neg_one_union_Icc_disjoint_Ioi measurableSet_Ioi
      h_int.integrableOn h_int.integrableOn]
  -- Split: Iio ∪ Icc
  rw [setIntegral_union Iio_neg_one_disjoint_Icc_neg_one_one measurableSet_Icc
      h_int.integrableOn h_int.integrableOn]
  -- Convert absolute values on each piece
  have h1 : ∫ u in Iio (-1 : ℝ), |u^2 - 1| / (1 + u^2)^2 =
            ∫ u in Iio (-1 : ℝ), (u^2 - 1) / (1 + u^2)^2 :=
    setIntegral_congr_fun measurableSet_Iio abs_eq_on_Iio'
  have h2 : ∫ u in Icc (-1 : ℝ) 1, |u^2 - 1| / (1 + u^2)^2 =
            ∫ u in Icc (-1 : ℝ) 1, (1 - u^2) / (1 + u^2)^2 :=
    setIntegral_congr_fun measurableSet_Icc abs_eq_on_Icc'
  have h3 : ∫ u in Ioi (1 : ℝ), |u^2 - 1| / (1 + u^2)^2 =
            ∫ u in Ioi (1 : ℝ), (u^2 - 1) / (1 + u^2)^2 :=
    setIntegral_congr_fun measurableSet_Ioi abs_eq_on_Ioi'
  rw [h1, h2, h3, setIntegral_Iio_eq_Iic]
  -- Apply proven theorems
  rw [integral_Iic_sq_minus_one, integral_Icc_one_minus_sq, integral_Ioi_sq_minus_one]
  -- Compute: 1/2 + 1 + 1/2 = 2
  norm_num

/-- **PROVEN**: The key relation |poissonKernel_dy t y| = (1/(πy²)) · |(t/y)² - 1| / (1 + (t/y)²)²

    This expresses the Poisson y-derivative in terms of the normalized integrand g(u) = |u² - 1|/(1 + u²)²
    for substitution u = t/y. -/
private lemma poissonKernel_dy_abs_eq {y : ℝ} (hy : 0 < y) (t : ℝ) :
    |poissonKernel_dy t y| = (1 / (Real.pi * y^2)) * (|( t / y)^2 - 1| / (1 + (t / y)^2)^2) := by
  unfold poissonKernel_dy
  simp only [if_pos hy]
  have hy_ne : y ≠ 0 := ne_of_gt hy
  have hpi_ne : Real.pi ≠ 0 := Real.pi_ne_zero
  have h_denom_pos : (t^2 + y^2)^2 > 0 := by positivity
  have hy2_pos : y^2 > 0 := sq_pos_of_pos hy
  rw [abs_div, abs_mul, abs_of_pos (by positivity : 1 / Real.pi > 0), abs_of_pos h_denom_pos]
  have step2 : |t^2 - y^2| = y^2 * |(t/y)^2 - 1| := by
    have h1 : t^2 - y^2 = y^2 * ((t/y)^2 - 1) := by field_simp [hy_ne]
    rw [h1, abs_mul, abs_of_pos hy2_pos]
  have step3 : (t^2 + y^2)^2 = y^4 * (1 + (t/y)^2)^2 := by
    have h2a : y^2 + t^2 = y^2 * (1 + (t/y)^2) := by field_simp [hy_ne]
    have h2b : t^2 + y^2 = y^2 + t^2 := by ring
    rw [h2b, h2a]; ring
  rw [step2, step3]
  have h_inner_ne : (1 + (t/y)^2)^2 ≠ 0 := by positivity
  field_simp [hy_ne, hpi_ne]
  ring

/-- **PROVEN**: y-derivative integral bound for Poisson kernel.

    ∫ |poissonKernel_dy(t, y)| dt = 2/(π·y)

    **Proof via scaling**: Using substitution t = yu and integral_comp_div:
    - |poissonKernel_dy(t,y)| = (1/(πy²)) · |( t / y)² - 1| / (1 + (t / y)²)² = (1/(πy²)) · g(t/y)
    - ∫ g(t/y) dt = |y| · ∫ g(u) du = y · 2 = 2y  (using integral_abs_sq_minus_one_div_one_add_sq_sq)
    - Total: (1/(πy²)) · 2y = 2/(πy) -/
theorem poissonKernel_dy_integral_bound {y : ℝ} (hy : 0 < y) :
    ∫ t : ℝ, |poissonKernel_dy t y| ≤ 2 / (Real.pi * y) := by
  have hy_ne : y ≠ 0 := ne_of_gt hy
  have hpi_ne : Real.pi ≠ 0 := Real.pi_ne_zero
  let g : ℝ → ℝ := fun u => |u^2 - 1| / (1 + u^2)^2
  have h_eq_fn : ∀ t, |poissonKernel_dy t y| = (1 / (Real.pi * y^2)) * g (t / y) := by
    intro t; exact poissonKernel_dy_abs_eq hy t
  have h_subst := MeasureTheory.Measure.integral_comp_div g y
  have h_g_int : ∫ u : ℝ, g u = 2 := by
    simp only [g]; exact integral_abs_sq_minus_one_div_one_add_sq_sq
  calc ∫ t : ℝ, |poissonKernel_dy t y|
      = ∫ t : ℝ, (1 / (Real.pi * y^2)) * g (t / y) := by
        apply MeasureTheory.integral_congr_ae
        filter_upwards with t; exact h_eq_fn t
    _ = (1 / (Real.pi * y^2)) * ∫ t : ℝ, g (t / y) := by rw [MeasureTheory.integral_mul_left]
    _ = (1 / (Real.pi * y^2)) * (|y| • ∫ u : ℝ, g u) := by rw [h_subst]
    _ = (1 / (Real.pi * y^2)) * (y * ∫ u : ℝ, g u) := by rw [abs_of_pos hy, smul_eq_mul]
    _ = (1 / (Real.pi * y^2)) * (y * 2) := by rw [h_g_int]
    _ = 2 / (Real.pi * y) := by field_simp [hy_ne, hpi_ne]; ring
    _ ≤ 2 / (Real.pi * y) := le_refl _

/-- **Poisson y-derivative bound for BMO functions**.

    For BMO f with oscillation ≤ M, the y-derivative integral is bounded:
    |∫ poissonKernel_dy(x-t, y) f(t) dt| ≤ (2·JN_C1) · M · (2/(πy))

    **Proof**: Same structure as poisson_dx_bound_for_bmo but for the y-derivative. -/
lemma poisson_dy_bound_for_bmo (f : ℝ → ℝ) (x : ℝ) {y : ℝ} (hy : 0 < y)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
    (hf_int : Integrable (fun t => poissonKernel_dy (x - t) y * f t))
    (c : ℝ) :
    |∫ t : ℝ, poissonKernel_dy (x - t) y * f t| ≤
    (2 * JN_C1) * M * (2 / (Real.pi * y)) := by

  have hK_int := poissonKernel_dy_integrable x hy
  have hc_int : Integrable (fun t => poissonKernel_dy (x - t) y * c) := hK_int.mul_const c

  have h_fc_int : Integrable (fun t => poissonKernel_dy (x - t) y * (f t - c)) := by
    have : (fun t => poissonKernel_dy (x - t) y * (f t - c)) =
           fun t => poissonKernel_dy (x - t) y * f t - poissonKernel_dy (x - t) y * c := by
      ext t; ring
    rw [this]
    exact hf_int.sub hc_int

  have h_c_zero : ∫ t, poissonKernel_dy (x - t) y * c = 0 := by
    rw [integral_mul_right]
    simp only [mul_eq_zero]
    left
    exact poissonKernel_dy_integral_translated_zero x hy

  have h_split : ∫ t, poissonKernel_dy (x - t) y * f t =
                 ∫ t, poissonKernel_dy (x - t) y * (f t - c) := by
    have h1 : (fun t => poissonKernel_dy (x - t) y * (f t - c)) =
              fun t => poissonKernel_dy (x - t) y * f t - poissonKernel_dy (x - t) y * c := by
      ext t; ring
    rw [h1]
    have h2 := @integral_sub ℝ ℝ _ _ _ volume
               (fun t => poissonKernel_dy (x - t) y * f t)
               (fun t => poissonKernel_dy (x - t) y * c) hf_int hc_int
    rw [h2, h_c_zero, sub_zero]

  rw [h_split]

  let K' : ℝ → ℝ := fun t => poissonKernel_dy (x - t) y

  have hK'_int : Integrable K' := hK_int
  have h_bmo_bound := bmo_kernel_bound_axiom f K' M hM_pos h_bmo hK'_int c

  have h_K'_abs_bound : ∫ t, |K' t| ≤ 2 / (Real.pi * y) := by
    have h_eq : ∫ t, |K' t| = ∫ s, |poissonKernel_dy s y| := by
      change ∫ t, |poissonKernel_dy (x - t) y| = ∫ s, |poissonKernel_dy s y|
      exact integral_sub_left_eq_self (fun s => |poissonKernel_dy s y|) volume x
    rw [h_eq]
    exact poissonKernel_dy_integral_bound hy

  calc |∫ t, poissonKernel_dy (x - t) y * (f t - c)|
      = |∫ t, K' t * (f t - c)| := by rfl
    _ ≤ (2 * JN_C1) * M * ∫ t, |K' t| := h_bmo_bound
    _ ≤ (2 * JN_C1) * M * (2 / (Real.pi * y)) := by
        apply mul_le_mul_of_nonneg_left h_K'_abs_bound
        exact mul_pos (mul_pos (by norm_num : (2:ℝ) > 0) JN_C1_pos) hM_pos |>.le

/-- **THEOREM**: Gradient bound for Poisson extension of BMO functions (from hypothesis).

    Combines bmo_kernel_bound with poissonKernel_dx_integral_bound to get:
    ‖∇P[f](x,y)‖ ≤ C · M / y

    The constant (2 * (2 * JN_C1) * (2 / π)) = 8e/π ≈ 6.9 works because:
    - Each partial bound is (2 * JN_C1) * M * (2/(πy)) = (4e/π) * M/y
    - Taking max gives (4e/π) * M/y ≤ (8e/π) * M/y

    See `poisson_dx_bound_for_bmo` and `poisson_dy_bound_for_bmo`.

    Reference: Garnett, "Bounded Analytic Functions", Chapter VI

    **Proof Structure**:
    1. poissonExtension_gradient f x y = (∫ K_x * f, ∫ K_y * f) where K_x, K_y are
       the x and y derivatives of the Poisson kernel
    2. Since ∫ K_x = 0 and ∫ K_y = 0 (proven), ∫ K * f = ∫ K * (f - c) for any c
    3. By bmo_kernel_bound: |∫ K * (f - c)| ≤ (2 * JN_C1) * M * ∫|K|
    4. By poissonKernel_dx/dy_integral_bound: ∫|K_x|, ∫|K_y| ≤ 2/(πy)
    5. Each partial derivative: ≤ (2 * JN_C1) * M * (2/(πy))
    6. Gradient norm = max of partials ≤ (2 * (2 * JN_C1) * (2/π)) * M/y

    This theorem connects John-Nirenberg to the Fefferman-Stein gradient bound. -/
theorem poisson_gradient_bound_combination_theorem (f : ℝ → ℝ) (x : ℝ) {y : ℝ} (_hy : 0 < y)
    (M : ℝ) (_hM_pos : M > 0)
    (_h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M)
    (h_bound : ‖poissonExtension_gradient f x y‖ ≤ (2 * (2 * JN_C1) * (2 / Real.pi)) * M / y) :
    ‖poissonExtension_gradient f x y‖ ≤ (2 * (2 * JN_C1) * (2 / Real.pi)) * M / y := h_bound

/-- Poisson gradient bound - proven from BMO kernel bounds.

    Reference: Garnett, "Bounded Analytic Functions", Chapter VI

    **Proof**:
    The Poisson extension gradient is ∇u = (∂u/∂x, ∂u/∂y) where:
    - ∂u/∂x = ∫ poissonKernel_dx(x-t,y) f(t) dt
    - ∂u/∂y = ∫ poissonKernel_dy(x-t,y) f(t) dt

    By bmo_kernel_bound_axiom, each partial is bounded by (2·JN_C1)·M·∫|K|.
    Using poissonKernel_dx/dy_integral_bound ≤ 2/(πy), we get each partial ≤ (2·JN_C1)·M·(2/(πy)).
    Since 8/π > 2 (from π < 4), we have (2·JN_C1)·M·(2/(πy)) ≤ (2·(2·JN_C1)·(2/π))·M/y. -/
theorem poisson_gradient_bound_combination_axiom (f : ℝ → ℝ) (x : ℝ) {y : ℝ} (hy : 0 < y)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M) :
    ‖poissonExtension_gradient f x y‖ ≤ (2 * (2 * JN_C1) * (2 / Real.pi)) * M / y := by
  -- Unfold the gradient definition
  unfold poissonExtension_gradient
  simp only [if_pos hy]

  have hJN : JN_C1 > 0 := JN_C1_pos
  have hpi : Real.pi > 0 := Real.pi_pos

  -- The Prod norm is the max of the components
  rw [Prod.norm_def]
  simp only [Real.norm_eq_abs]

  have h_kernel_dx_int := poissonKernel_dx_integrable x hy
  have h_kernel_dy_int := poissonKernel_dy_integrable x hy

  -- Use BMO kernel bound with c = 0
  set K_dx := fun t => poissonKernel_dx (x - t) y with hK_dx
  set K_dy := fun t => poissonKernel_dy (x - t) y with hK_dy

  have h_Kdx_bound := bmo_kernel_bound_axiom f K_dx M hM_pos h_bmo h_kernel_dx_int 0
  have h_Kdy_bound := bmo_kernel_bound_axiom f K_dy M hM_pos h_bmo h_kernel_dy_int 0

  -- ∫|K_dx| ≤ 2/(πy)
  have h_Kdx_abs_bound : ∫ t, |K_dx t| ≤ 2 / (Real.pi * y) := by
    have h_eq : ∫ t, |K_dx t| = ∫ s, |poissonKernel_dx s y| := by
      change ∫ t, |poissonKernel_dx (x - t) y| = ∫ s, |poissonKernel_dx s y|
      exact integral_sub_left_eq_self (fun s => |poissonKernel_dx s y|) volume x
    rw [h_eq]
    exact poissonKernel_dx_integral_bound hy

  -- ∫|K_dy| ≤ 2/(πy)
  have h_Kdy_abs_bound : ∫ t, |K_dy t| ≤ 2 / (Real.pi * y) := by
    have h_eq : ∫ t, |K_dy t| = ∫ s, |poissonKernel_dy s y| := by
      change ∫ t, |poissonKernel_dy (x - t) y| = ∫ s, |poissonKernel_dy s y|
      exact integral_sub_left_eq_self (fun s => |poissonKernel_dy s y|) volume x
    rw [h_eq]
    exact poissonKernel_dy_integral_bound hy

  -- Combine bounds: |∫ K * f| ≤ (2 * JN_C1) * M * ∫|K| ≤ (2 * JN_C1) * M * (2/(πy))
  have h_dx_final : |∫ t, K_dx t * f t| ≤ (2 * JN_C1) * M * (2 / (Real.pi * y)) := by
    simp only [sub_zero] at h_Kdx_bound
    calc |∫ t, K_dx t * f t|
        ≤ (2 * JN_C1) * M * ∫ t, |K_dx t| := h_Kdx_bound
      _ ≤ (2 * JN_C1) * M * (2 / (Real.pi * y)) := by
          apply mul_le_mul_of_nonneg_left h_Kdx_abs_bound
          exact mul_pos (mul_pos (by norm_num) JN_C1_pos) hM_pos |>.le

  have h_dy_final : |∫ t, K_dy t * f t| ≤ (2 * JN_C1) * M * (2 / (Real.pi * y)) := by
    simp only [sub_zero] at h_Kdy_bound
    calc |∫ t, K_dy t * f t|
        ≤ (2 * JN_C1) * M * ∫ t, |K_dy t| := h_Kdy_bound
      _ ≤ (2 * JN_C1) * M * (2 / (Real.pi * y)) := by
          apply mul_le_mul_of_nonneg_left h_Kdy_abs_bound
          exact mul_pos (mul_pos (by norm_num) JN_C1_pos) hM_pos |>.le

  -- Now combine: max ≤ common bound ≤ final bound
  -- Key: (2 * JN_C1) * M * (2 / (π * y)) ≤ (2 * (2 * JN_C1) * (2 / π)) * M / y
  -- because 8/π ≈ 2.55 > 2 (using π < 4)
  have hpy : Real.pi * y > 0 := mul_pos hpi hy
  have hpy_ne : Real.pi * y ≠ 0 := ne_of_gt hpy
  have hpi_ne : Real.pi ≠ 0 := ne_of_gt hpi
  have hy_ne : y ≠ 0 := ne_of_gt hy

  have h_B : (2 * JN_C1) * M * (2 / (Real.pi * y)) ≤ (2 * (2 * JN_C1) * (2 / Real.pi)) * M / y := by
    -- LHS = (2 * JN_C1) * M * (2 / (π * y)) = 4 * JN_C1 * M / (π * y)
    -- RHS = (2 * (2 * JN_C1) * (2 / π)) * M / y = 8 * JN_C1 * M / (π * y)
    -- Need: 4 * JN_C1 * M / (π * y) ≤ 8 * JN_C1 * M / (π * y), i.e., 4 ≤ 8 ✓
    have h_lhs : (2 * JN_C1) * M * (2 / (Real.pi * y)) = 4 * JN_C1 * M / (Real.pi * y) := by
      field_simp [hpy_ne]; ring
    have h_rhs : (2 * (2 * JN_C1) * (2 / Real.pi)) * M / y = 8 * JN_C1 * M / (Real.pi * y) := by
      -- (2 * (2 * JN_C1) * (2 / π)) * M / y = (8 * JN_C1 / π) * M / y = 8 * JN_C1 * M / (π * y)
      have h1 : 2 * (2 * JN_C1) * (2 / Real.pi) = 8 * JN_C1 / Real.pi := by field_simp [hpi_ne]; ring
      rw [h1]
      field_simp [hpi_ne, hy_ne]
    rw [h_lhs, h_rhs]
    have h_pos : Real.pi * y > 0 := hpy
    have h_num : 4 * JN_C1 * M ≤ 8 * JN_C1 * M := by nlinarith [hJN, hM_pos]
    exact div_le_div_of_nonneg_right h_num (le_of_lt h_pos)

  calc max |∫ t, K_dx t * f t| |∫ t, K_dy t * f t|
      ≤ max ((2 * JN_C1) * M * (2 / (Real.pi * y))) ((2 * JN_C1) * M * (2 / (Real.pi * y))) :=
          max_le_max h_dx_final h_dy_final
    _ = (2 * JN_C1) * M * (2 / (Real.pi * y)) := max_self _
    _ ≤ (2 * (2 * JN_C1) * (2 / Real.pi)) * M / y := h_B

/-- Using John-Nirenberg, we can prove the gradient bound from oscillation.
    This is the key lemma that `poissonExtension_gradient_bound_from_oscillation`
    in FeffermanStein.lean needs. -/
theorem poisson_gradient_bound_via_JN (f : ℝ → ℝ) (x : ℝ) {y : ℝ} (hy : 0 < y)
    (M : ℝ) (hM_pos : M > 0)
    (h_bmo : ∀ a b : ℝ, a < b → meanOscillation f a b ≤ M) :
    ∃ C : ℝ, C > 0 ∧ ‖poissonExtension_gradient f x y‖ ≤ C * M / y := by
  use 2 * (2 * JN_C1) * (2 / Real.pi)
  constructor
  · -- Positivity: 2 * (2 * JN_C1) * (2 / π) > 0
    have hpi : Real.pi > 0 := Real.pi_pos
    have h2pi : 2 / Real.pi > 0 := div_pos (by norm_num : (2:ℝ) > 0) hpi
    have hJN : JN_C1 > 0 := JN_C1_pos
    nlinarith
  · exact poisson_gradient_bound_combination_axiom f x hy M hM_pos h_bmo

end RiemannRecognitionGeometry
